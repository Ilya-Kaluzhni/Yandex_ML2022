{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yandexdataschool/MLatImperial2022/blob/main/Seminars/lab_04_ROC_AUC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdTl5bKzs2sY"
      },
      "source": [
        "# Confusion matrix\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8trYaBos2sc"
      },
      "source": [
        "     sklearn.metrics.confusion_matrix(y_true, y_pred, *, labels=None, sample_weight=None, normalize=None)\n",
        " \n",
        "     where the normalize parameter takes the values {'true', 'pred', 'all'} - normalization, respectively, by rows (True classes), by columns (Predicted classes) or normalization by the total number of objects in the sample.\n",
        "     The default value is normalize=None (each cell of the matrix will contain the number of  objects)\n",
        "     \n",
        "#### For a simple visualization of confusion matrix, we use the class:\n",
        "\n",
        "    sklearn.metrics.ConfusionMatrixDisplay(confusion_matrix, *, display_labels=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7qeQ0JoAs2se"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.datasets import load_wine\n",
        "X, y = load_wine(return_X_y=True)\n",
        "X.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_OHTb8Ds2sh"
      },
      "source": [
        "#### Fit model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FtguzFTRs2sh"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2,\n",
        "                                                    random_state=0)\n",
        "clf = LogisticRegression(multi_class='ovr',max_iter=1000)\n",
        "clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CB8nXF1Xs2si"
      },
      "source": [
        "Display the confusion matrix on the training sample with the number of samples in each group"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ffEvy4R0s2sj"
      },
      "outputs": [],
      "source": [
        "from pylab import rcParams\n",
        "rcParams['figure.figsize'] = 4,4\n",
        "\n",
        "predictions = clf.predict(X_test)\n",
        "cm = confusion_matrix(y_test, predictions, labels=clf.classes_)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
        "                              display_labels=clf.classes_)\n",
        "disp.plot()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZaGqWGMs2sk"
      },
      "source": [
        "#### Display the confusion matrix on the test sample with the share of samples in each group"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z5OiLnnZs2sk"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "predictions = clf.predict(X_test)\n",
        "cm = confusion_matrix(y_test, predictions, labels=clf.classes_,normalize='true')\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
        "                              display_labels=clf.classes_)\n",
        "disp.plot()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qM1j3rnzs2sl"
      },
      "source": [
        "# Quality metrics for 2-class tasks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAP8Iy0ss2sm"
      },
      "source": [
        "#### Let's take a 2-class task with customers' churn from a telecom operator.\n",
        "\n",
        "It is important for us to train the model to predict class '1' (customer churn) well in order to efficiently allocate marketing resources to customers with a high probability of churn. At the same time, there are 6 times fewer observations of class 1 in the sample than of class 0. And, using the dummy model, we will immediately get a good accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mI0BzmOAs2sn"
      },
      "source": [
        "But among all the customers we want to  predict those with a large expected LTV(life-time value).\n",
        "\n",
        "Then we need:\n",
        "1. fit a regression model that predicts LTV\n",
        "2. fit a classification model that predict probability of churn very well\n",
        "3. treat LTV * probability(churn) as expected loss for each customer\n",
        "4. select customers with greater loss for marketing company or bonus scheme\n",
        "\n",
        "But how to detect which models are good at probability prediction?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u0BGlT-ts2so"
      },
      "outputs": [],
      "source": [
        "!wget -N https://github.com/yandexdataschool/MLatImperial2022/main/blob/telecom_churn2.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qh5XN7xms2sr"
      },
      "outputs": [],
      "source": [
        "# telecom company data preparation\n",
        "from matplotlib.pylab import rc, plot\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import precision_recall_curve, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegressionCV,LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
        "random_state=0\n",
        "df = pd.read_csv('telecom_churn2.csv')\n",
        "d = {'Yes' : 1, 'No' : 0}\n",
        "df['International plan'] = df['International plan'].map(d)\n",
        "df['Voice mail plan'] = df['Voice mail plan'].map(d)\n",
        "df['Churn'] = df['Churn'].astype('int64')\n",
        "df=df.drop('State',axis=1)\n",
        "\n",
        "y=df['Churn']\n",
        "X=df.drop('Churn',axis=1)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2,     random_state=0)\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "numeric_data = X_train.select_dtypes([np.number])\n",
        "numeric_data_mean = numeric_data.mean()\n",
        "X_train = X_train.fillna(numeric_data_mean)\n",
        "X_test = X_test.fillna(numeric_data_mean)\n",
        "X_train.head()\n",
        "                                                    \n",
        "numeric_features = numeric_data.columns\n",
        "categorical = list(X_train.dtypes[X_train.dtypes == \"object\"].index)\n",
        "X_train[categorical] = X_train[categorical].fillna(\"NotGiven\")\n",
        "X_test[categorical] = X_test[categorical].fillna(\"NotGiven\")     \n",
        "\n",
        "\n",
        "column_transformer = ColumnTransformer([\n",
        "    ('ohe', OneHotEncoder(handle_unknown=\"ignore\",sparse=False), categorical),\n",
        "    ('scaling', StandardScaler(), numeric_features)\n",
        "])\n",
        "X_train_transformed=column_transformer.fit_transform(X_train)\n",
        "X_test_transformed=column_transformer.fit_transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdaS61R2s2su"
      },
      "source": [
        "#### Fit logistic regression model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "njBA1AHos2su"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "\n",
        "model=LogisticRegressionCV(penalty='l2',Cs=[0.0001,0.001,0.01,0.1,1,10,100],cv=5,\n",
        "                                       random_state=0)\n",
        "model.fit(X_train_transformed,y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpapK6KKs2sv"
      },
      "source": [
        "#### Calculate accuracy_score:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RC3Ne6MXs2sw"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "y_pred = model.predict(X_test_transformed)\n",
        "print(accuracy_score(y_test,y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-x052kE2s2sx"
      },
      "source": [
        "#### Assuming by the accuracy_score, the resulting model seems to be pretty good\n",
        "\n",
        "#### Make the confusion matrix:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P-QDdj1ys2s0"
      },
      "outputs": [],
      "source": [
        "\n",
        "cm = confusion_matrix(y_test, y_pred,labels=model.classes_)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
        "                              display_labels=model.classes_)\n",
        "disp.plot()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqWppYt8s2s2"
      },
      "source": [
        "#### From the confusion matrix, we can see that the classes are highly imbalanced. Even though the accuracy_score is not bad, only a minority of the objects in class '1' are predicted correctly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_x0baJpFs2s2"
      },
      "source": [
        "It is much more useful to focus on metrics:\n",
        "\n",
        "1) precision (precision)\n",
        "2) completeness (recall)\n",
        "3) F-measures\n",
        "4) weighted F-measure\n",
        "\n",
        "<center>\n",
        "<img src=\"https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F3292712%2F4fc7e8af4d3ecfd15c73f72fba82d027%2FconfusionMatrxiUpdated.jpg?generation=1574221845511874&alt=media\" width=50%/>\n",
        "</center>\n",
        "\n",
        "\n",
        "To calculate these metrics, we will use the classes:\n",
        "\n",
        "- sklearn.metrics.precision_score(y_true, y_pred,...)\n",
        "- sklearn.metrics.recall_score(y_true, y_pred,...)\n",
        "- sklearn.metrics.f1_score(y_true, y_pred,...)\n",
        "- sklearn.metrics.fbeta_score(y_true, y_pred, *, beta,...)\n",
        "\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/Precisionrecall.svg/700px-Precisionrecall.svg.png\" width=30%/>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "The **precision** is intuitively the ability of the classifier not to label as positive a sample that is negative.\n",
        "\n",
        "The **recall** is intuitively the ability of the classifier to find all the positive samples.\n",
        "\n",
        "The **F1** score can be interpreted as a weighted average of the precision and recall\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pNVCoYc_s2s3"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score,recall_score\n",
        "from sklearn.metrics import f1_score, fbeta_score\n",
        "def print_metrics(y_test, y_pred):\n",
        "    print(f'precision_score={precision_score(y_test, y_pred):.3f}')\n",
        "    print(f'recall_score={recall_score(y_test, y_pred):.3f}')\n",
        "    print(f'f1_score={f1_score(y_test, y_pred):.3f}')\n",
        "    print(f'f_score (beta=2)={fbeta_score(y_test, y_pred, beta=2):.3f}')\n",
        "    print(f'f_score (beta=4)={fbeta_score(y_test, y_pred, beta=4):.3f}')\n",
        "    \n",
        "print_metrics(y_test, y_pred)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0I6Tqi3is2s4"
      },
      "source": [
        "## ROC curve"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksfscN6ds2s4"
      },
      "source": [
        "To get ROC curve we will change the decision rule according to which we assign an object to a positive class. More precisely, we will adjust $\\alpha$, where\n",
        "\n",
        "$$\\hat y(x) = sign(\\beta^T x - \\alpha)$$\n",
        "$$TPR = TPR(\\alpha)$$\n",
        "$$FPR = FPR(\\alpha)$$\n",
        "The area under the curve is calculated by the formula:\n",
        "$$AUC = \\int_{-\\infty}^{\\infty} {TPR} \\,d{FPR}$$\n",
        "\n",
        "\n",
        "<img src=\"https://editor.analyticsvidhya.com/uploads/23302main-qimg-7fc9e8601c15e33945720800aa237a7f.png\" width=50%/>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ra5hQlRfs2s5"
      },
      "source": [
        "### Plotting of ROC curve\n",
        "\n",
        "        sklearn.metrics.plot_roc_curve(estimator, X, y, *,...)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hp7EeY9is2s5"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import plot_roc_curve\n",
        "\n",
        "fig = plt.figure(figsize=(5,5))\n",
        "ax = fig.add_subplot( 1, 1, 1 )\n",
        "plt.plot([0.2, 0.2], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plot_roc_curve(model,X_test_transformed,y_test,ax=ax);\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ta-79sAqs2s6"
      },
      "source": [
        "http://arogozhnikov.github.io/RocCurve.html\n",
        "\n",
        "http://arogozhnikov.github.io/2015/10/05/roc-curve.html\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TrB7vBHs2s6"
      },
      "source": [
        "\n",
        "### Let's compare ROC curves of different models\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iejnC7DXs2s6"
      },
      "source": [
        "Accuracy baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ZGtFlIds2s7"
      },
      "outputs": [],
      "source": [
        "\n",
        "1-y.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W8ewx9Qys2s7"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier,BaggingClassifier,GradientBoostingClassifier\n",
        "#fit models\n",
        "base_model=DecisionTreeClassifier()\n",
        "svc = SVC(kernel='rbf',gamma=1,probability=True)\n",
        "svc.fit(X_train_transformed, y_train)\n",
        "knn = KNeighborsClassifier(n_neighbors=10)\n",
        "knn.fit(X_train_transformed, y_train)\n",
        "tree=DecisionTreeClassifier(max_depth=10)\n",
        "tree.fit(X_train_transformed,y_train)\n",
        "logreg=LogisticRegressionCV(penalty='l2',Cs=[0.0001,0.001,0.01,0.1,1,10,100],cv=5,\n",
        "                                       random_state=0)\n",
        "logreg.fit(X_train_transformed, y_train)\n",
        "forest = RandomForestClassifier(n_estimators=89,max_samples=0.8,random_state=0)\n",
        "forest.fit(X_train_transformed, y_train)\n",
        "bagging = BaggingClassifier(base_estimator=base_model,max_samples=0.9,max_features=1.0,\n",
        "                        n_estimators=21, random_state=0)\n",
        "bagging.fit(X_train_transformed, y_train)\n",
        "boost = GradientBoostingClassifier(n_estimators=150, learning_rate=0.1,\n",
        "    max_depth=5, random_state=0)\n",
        "boost.fit(X_train_transformed, y_train)\n",
        "\n",
        "\n",
        "#plot roc curves\n",
        "plt.figure(figsize=(12,12))\n",
        "log_disp = plot_roc_curve(logreg, X_test_transformed, y_test)\n",
        "svc_disp = plot_roc_curve(svc, X_test_transformed, y_test, ax=log_disp.ax_)\n",
        "knn_disp = plot_roc_curve(knn, X_test_transformed, y_test, ax=log_disp.ax_)\n",
        "forest_disp = plot_roc_curve(forest, X_test_transformed, y_test, ax=log_disp.ax_)\n",
        "bagging_disp = plot_roc_curve(bagging, X_test_transformed, y_test, ax=log_disp.ax_)\n",
        "boosting_disp = plot_roc_curve(boost, X_test_transformed, y_test, ax=log_disp.ax_)\n",
        "tree_disp = plot_roc_curve(tree, X_test_transformed, y_test, ax=log_disp.ax_)\n",
        "plt.plot([0.08, 0.08], [0, 1],'r--')\n",
        "plt.title((\"ROC curve comparison\"))\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hz-q5RA6s2s8"
      },
      "source": [
        "http://arogozhnikov.github.io/RocCurve.html\n",
        "\n",
        "http://arogozhnikov.github.io/2015/10/05/roc-curve.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZTy1_Igs2s8"
      },
      "source": [
        "Let's imaging that for each correct guess about new object you are paid. But the cost for correctly guessing signal and background are different.\n",
        "\n",
        "To maximize the income, the threshold for decision rule should correspond to point at ROC curve, where loss is minumum\n",
        "\n",
        "One of such examples is email spam filtering: cost for incorrect classification of good letter is times higher than cost for making wrong prediction for spam letter.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hi5AcVg-s2s9"
      },
      "source": [
        "#### TP-TN distribution graphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "CXDqsS7Cs2s9"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.simplefilter(\"ignore\")\n",
        "clfs = [tree,knn,boost,forest,svc,logreg]\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "plt.figure(figsize=(12, 12))\n",
        "\n",
        "for i, clf in enumerate(clfs):\n",
        "    plt.subplot(2, 3,  i+1)    \n",
        "    probabilities=clf.predict_proba(X_test_transformed)[:, 1]\n",
        "    y_test_prob=np.concatenate((probabilities[:,np.newaxis],y_test[:,None]),axis=1)\n",
        "    tp=y_test_prob[y_test_prob[:,1]>0]\n",
        "    tn=y_test_prob[y_test_prob[:,1]<1]\n",
        "\n",
        "    sns.distplot(tn[:,0],bins=60,hist=True,kde=True,label=\"True Negatives\")\n",
        "    sns.distplot(tp[:,0],bins=60,hist=True,kde=True,label=\"True Positives\")\n",
        "\n",
        "\n",
        "    y_pred=clf.predict_proba(X_test_transformed)[:,1]\n",
        "    roc_auc = roc_auc_score(y_test, y_pred)*100\n",
        "    plt.title(f\"{clf.__class__.__name__},AUC={str(roc_auc.round(0))}\", fontsize=12)\n",
        "    \n",
        "    plt.xlabel(\"Predicted probability of positive class\")\n",
        "    plt.legend()\n",
        "  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3mpEwsEs2s-"
      },
      "source": [
        "###  AUC ROC:\n",
        "        \n",
        "        sklearn.metrics.roc_auc_score(y_true, y_score, *, ...)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CHhxl8z8s2s_"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "y_pred=logreg.predict_proba(X_test)[:,1]\n",
        "roc_auc = roc_auc_score(y_test, y_pred)\n",
        "print(roc_auc.round(4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2clHK9js2s_"
      },
      "source": [
        "###  brier score \n",
        "MSE of probabilities vs targers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "Ga9w9ahZs2tA"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import brier_score_loss\n",
        "for clf in [logreg,knn,bagging,forest] :\n",
        "    y_prob=clf.predict_proba(X_test)\n",
        "    brier = brier_score_loss(y_test, y_prob[:,1])\n",
        "    print(type(clf).__name__,':',brier.round(3))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4BhLXcPDs2tA"
      },
      "outputs": [],
      "source": [
        "#<YOUR TURN>\n",
        "#fit any model on this data using GridSearchCV with scoring='recall'\n",
        "#is there any difference in best_params_ comaring to using default scoring method?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlB_eNt4s2tB"
      },
      "source": [
        "## Bonus part: model's calibration."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_fPSKvAs2tB"
      },
      "source": [
        "Reliability diagramms are used to assess how well the model is calibrated.\n",
        "\n",
        "Reliability is a measure about the alignment of the model confidence and the model real performance. A reliable model is able to reflect its real performance through the confidence that it has over the samples. So we can direct evaluate the usability of the model through the evaluation of the confidence that it has during inference. This gives us a very descent and efficient method for such evaluation.\n",
        "\n",
        "Reliability diagram\n",
        "\n",
        "Before we go into quantify the measure, first we need to construct a reliability diagram. To construct it, we will do the followings:\n",
        "split the confidence space into several bins with constant separation.\n",
        "run the model on the test data and allocate them with respect to the confidence of them.\n",
        "compute the expectation accuracy of each bins and plot them as accuracy vs confidence.\n",
        "\n",
        "The diagonal indicates a perfect reliability. The dotted horizontal line is the no resolution line, indicating the mean probability in the bin. \n",
        "\n",
        "<img src=https://miro.medium.com/max/700/1*ia-FW6n6SsSCeCJib0POfA.png width=\"500\" height=\"500\" />\n",
        "\n",
        "\n",
        "If the blue bar is higher than the pink one, the model is said to be under-confident (**under-confident**), if it is lower, it is said to be over-confident or “over-confident” (**over-confident**).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbpQv7nKs2tP"
      },
      "outputs": [],
      "source": [
        "from sklearn.calibration import calibration_curve\n",
        "# predict probabilities\n",
        "for clf in [forest,bagging,logreg,boost]:\n",
        "    probs = clf.predict_proba(X_train_transformed)[:,1]\n",
        "    # reliability diagram\n",
        "    fop, mpv = calibration_curve(y_train, probs, n_bins=20)\n",
        "\n",
        "    # plot model reliability\n",
        "    plt.plot(mpv, fop, marker='.',label=type(clf).__name__)\n",
        "    plt.title(\"reliability diagram train\")\n",
        "    plt.legend()\n",
        "# plot perfectly calibrated\n",
        "plt.plot([0, 1], [0, 1], linestyle='--')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFjptpYws2tP"
      },
      "source": [
        "class sklearn.calibration.CalibratedClassifierCV(base_estimator=None, *, method='sigmoid', cv=None, n_jobs=None, ensemble=True)\n",
        "- method{‘sigmoid’, ‘isotonic’}, default=’sigmoid’\n",
        "- cvint, cross-validation generator, iterable or “prefit”"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPwpg1PGs2tQ"
      },
      "source": [
        "Random forest calibration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_lWq5BrJs2tQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "calibrated_forest = CalibratedClassifierCV(base_estimator=forest,method='isotonic', cv='prefit')\n",
        "calibrated_forest.fit(X_train_transformed,y_train)\n",
        "calibrated_tree = CalibratedClassifierCV(base_estimator=tree,method='isotonic', cv='prefit')\n",
        "calibrated_tree.fit(X_train_transformed,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9x5BOAxMs2tQ"
      },
      "outputs": [],
      "source": [
        "for clf in [forest,boost,bagging,logreg]:\n",
        "    calibrated_model = CalibratedClassifierCV(base_estimator=clf,method='isotonic',cv=3)\n",
        "    calibrated_model.fit(X_train_transformed,y_train)\n",
        "    probs = calibrated_model.predict_proba(X_test_transformed)[:,1]\n",
        "    \n",
        "    # reliability diagram\n",
        "    fop, mpv = calibration_curve(y_test, probs, n_bins=10)\n",
        "    # plot perfectly calibrated\n",
        "\n",
        "    # plot model reliability\n",
        "    plt.plot(mpv, fop, marker='.',label=type(clf).__name__)\n",
        "    plt.legend()\n",
        "# plot perfectly calibrated\n",
        "plt.plot([0, 1], [0, 1], linestyle='--')    \n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTzLDhtDs2tR"
      },
      "source": [
        "#### Often we need model with good calibrability (ability to be calibrated well) and appropiate ROC AUC. (or we can choose the best model among models with the same ROC AUC by calibarability on a certain interval  of probabilities. For example if we won't   take into account customers with probability<0.7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEArbNzPs2tR"
      },
      "source": [
        "See also: Kolmogorov-Smirnov distance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDhRQ2A1s2tS"
      },
      "source": [
        "### Bonus part 2: Multiclass classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4IBAZZIs2tS"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://drek4537l1klr.cloudfront.net/rhys/v-3/Figures/CH06_FIG_8_MLR.png\" width=50%/>\n",
        "</center>\n",
        "\n",
        "### One versus all:\n",
        "\n",
        "<img src=\"https://paros-hotels.biz/images/machine/Difference-between-classification-and-clustering-in-data-mining-closed-5.png\" width=50%/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwixI0PSs2tS"
      },
      "source": [
        "#### One vs all"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emRReaXzs2tT"
      },
      "source": [
        "One-vs-rest (OvR for short, also referred to as One-vs-All or OvA) is a heuristic method for using binary classification algorithms for multi-class classification.\n",
        "\n",
        "It involves splitting the multi-class dataset into multiple binary classification problems. A binary classifier is then trained on each binary classification problem and predictions are made using the model that is the most confident."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvCs6Ctfs2tT"
      },
      "source": [
        "Some classifier has parametr *multi_class*. For instance, for Logistic Regression we have:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A57skqtns2tT"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, n_classes=3, random_state=1)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 0)\n",
        "\n",
        "model = LogisticRegression(multi_class='ovr')\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "y_proba = model.predict_proba(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yeTotZxds2tU"
      },
      "outputs": [],
      "source": [
        "X.shape, y.shape, X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cci85Uwes2tU"
      },
      "outputs": [],
      "source": [
        "y_pred.shape, y_proba.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hyWfu1F4s2tV"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DaQTz4Ls2tV"
      },
      "source": [
        "Another approach is to use implemented in sklearn OneVsRestClassifier:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0w2JlOoGs2tW"
      },
      "outputs": [],
      "source": [
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "\n",
        "model = LogisticRegression()\n",
        "\n",
        "ovr = OneVsRestClassifier(model)\n",
        "ovr.fit(X_train, y_train)\n",
        "y_pred = ovr.predict(X_test)\n",
        "y_proba = ovr.predict_proba(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ys2PkGtMs2tW"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRcAInmhs2tW"
      },
      "source": [
        "Look at metrics, they are exactly the same as in previous case."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "On0HtsRRs2tX"
      },
      "source": [
        "**One vs one**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1byKKC0s2tX"
      },
      "source": [
        "One-Vs-One for Multi-Class Classification\n",
        "One-vs-One (OvO for short) is another heuristic method for using binary classification algorithms for multi-class classification.\n",
        "\n",
        "Like one-vs-rest, one-vs-one splits a multi-class classification dataset into binary classification problems. Unlike one-vs-rest that splits it into one binary dataset for each class, the one-vs-one approach splits the dataset into one dataset for each class versus every other class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RoZoUo8ms2tX"
      },
      "outputs": [],
      "source": [
        "from sklearn.multiclass import OneVsOneClassifier\n",
        "\n",
        "model = LogisticRegression()\n",
        "ovo = OneVsOneClassifier(model)\n",
        "ovo.fit(X_train, y_train)\n",
        "y_pred = ovo.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iIIOCxh3s2tY"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "lab_04_ROC_AUC.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}