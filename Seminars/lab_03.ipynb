{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  <a href=\"https://colab.research.google.com/github/ikitova/MLatImperial2022/main/blob/lab_02_03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear classification for real task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll try to solve clients' churn task using data of mobile network operator.\n",
    "\n",
    "We have to predict whether customer will change the mobile network operator.\n",
    "\n",
    "The target field here is 'Churn'.\n",
    "\n",
    "Let's transform raw data, then make a Logistic Regression model and adjust it's parameteres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload data and have a look at it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://github.com/ikitova/MLatImperial2022/main/blob/telecom_churn.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Account length</th>\n",
       "      <th>Area code</th>\n",
       "      <th>International plan</th>\n",
       "      <th>Voice mail plan</th>\n",
       "      <th>Number vmail messages</th>\n",
       "      <th>Total day minutes</th>\n",
       "      <th>Total day calls</th>\n",
       "      <th>Total day charge</th>\n",
       "      <th>Total eve minutes</th>\n",
       "      <th>Total eve calls</th>\n",
       "      <th>Total eve charge</th>\n",
       "      <th>Total night minutes</th>\n",
       "      <th>Total night calls</th>\n",
       "      <th>Total night charge</th>\n",
       "      <th>Total intl minutes</th>\n",
       "      <th>Total intl calls</th>\n",
       "      <th>Total intl charge</th>\n",
       "      <th>Customer service calls</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KS</td>\n",
       "      <td>128</td>\n",
       "      <td>415</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>25</td>\n",
       "      <td>265.1</td>\n",
       "      <td>110</td>\n",
       "      <td>45.07</td>\n",
       "      <td>197.4</td>\n",
       "      <td>99</td>\n",
       "      <td>16.78</td>\n",
       "      <td>244.7</td>\n",
       "      <td>91</td>\n",
       "      <td>11.01</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OH</td>\n",
       "      <td>107</td>\n",
       "      <td>415</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>26</td>\n",
       "      <td>161.6</td>\n",
       "      <td>123</td>\n",
       "      <td>27.47</td>\n",
       "      <td>195.5</td>\n",
       "      <td>103</td>\n",
       "      <td>16.62</td>\n",
       "      <td>254.4</td>\n",
       "      <td>103</td>\n",
       "      <td>11.45</td>\n",
       "      <td>13.7</td>\n",
       "      <td>3</td>\n",
       "      <td>3.70</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NJ</td>\n",
       "      <td>137</td>\n",
       "      <td>415</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>243.4</td>\n",
       "      <td>114</td>\n",
       "      <td>41.38</td>\n",
       "      <td>121.2</td>\n",
       "      <td>110</td>\n",
       "      <td>10.30</td>\n",
       "      <td>162.6</td>\n",
       "      <td>104</td>\n",
       "      <td>7.32</td>\n",
       "      <td>12.2</td>\n",
       "      <td>5</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OH</td>\n",
       "      <td>84</td>\n",
       "      <td>408</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>299.4</td>\n",
       "      <td>71</td>\n",
       "      <td>50.90</td>\n",
       "      <td>61.9</td>\n",
       "      <td>88</td>\n",
       "      <td>5.26</td>\n",
       "      <td>196.9</td>\n",
       "      <td>89</td>\n",
       "      <td>8.86</td>\n",
       "      <td>6.6</td>\n",
       "      <td>7</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OK</td>\n",
       "      <td>75</td>\n",
       "      <td>415</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>166.7</td>\n",
       "      <td>113</td>\n",
       "      <td>28.34</td>\n",
       "      <td>148.3</td>\n",
       "      <td>122</td>\n",
       "      <td>12.61</td>\n",
       "      <td>186.9</td>\n",
       "      <td>121</td>\n",
       "      <td>8.41</td>\n",
       "      <td>10.1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.73</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  State  Account length  Area code International plan Voice mail plan  \\\n",
       "0    KS             128        415                 No             Yes   \n",
       "1    OH             107        415                 No             Yes   \n",
       "2    NJ             137        415                 No              No   \n",
       "3    OH              84        408                Yes              No   \n",
       "4    OK              75        415                Yes              No   \n",
       "\n",
       "   Number vmail messages  Total day minutes  Total day calls  \\\n",
       "0                     25              265.1              110   \n",
       "1                     26              161.6              123   \n",
       "2                      0              243.4              114   \n",
       "3                      0              299.4               71   \n",
       "4                      0              166.7              113   \n",
       "\n",
       "   Total day charge  Total eve minutes  Total eve calls  Total eve charge  \\\n",
       "0             45.07              197.4               99             16.78   \n",
       "1             27.47              195.5              103             16.62   \n",
       "2             41.38              121.2              110             10.30   \n",
       "3             50.90               61.9               88              5.26   \n",
       "4             28.34              148.3              122             12.61   \n",
       "\n",
       "   Total night minutes  Total night calls  Total night charge  \\\n",
       "0                244.7                 91               11.01   \n",
       "1                254.4                103               11.45   \n",
       "2                162.6                104                7.32   \n",
       "3                196.9                 89                8.86   \n",
       "4                186.9                121                8.41   \n",
       "\n",
       "   Total intl minutes  Total intl calls  Total intl charge  \\\n",
       "0                10.0                 3               2.70   \n",
       "1                13.7                 3               3.70   \n",
       "2                12.2                 5               3.29   \n",
       "3                 6.6                 7               1.78   \n",
       "4                10.1                 3               2.73   \n",
       "\n",
       "   Customer service calls  Churn  \n",
       "0                       1  False  \n",
       "1                       1  False  \n",
       "2                       0  False  \n",
       "3                       2  False  \n",
       "4                       3  False  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from matplotlib.pylab import rc, plot\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "random_state=0\n",
    "df = pd.read_csv('telecom_churn.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform target and  some other fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Account length</th>\n",
       "      <th>Area code</th>\n",
       "      <th>International plan</th>\n",
       "      <th>Voice mail plan</th>\n",
       "      <th>Number vmail messages</th>\n",
       "      <th>Total day minutes</th>\n",
       "      <th>Total day calls</th>\n",
       "      <th>Total day charge</th>\n",
       "      <th>Total eve minutes</th>\n",
       "      <th>Total eve calls</th>\n",
       "      <th>Total eve charge</th>\n",
       "      <th>Total night minutes</th>\n",
       "      <th>Total night calls</th>\n",
       "      <th>Total night charge</th>\n",
       "      <th>Total intl minutes</th>\n",
       "      <th>Total intl calls</th>\n",
       "      <th>Total intl charge</th>\n",
       "      <th>Customer service calls</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KS</td>\n",
       "      <td>128</td>\n",
       "      <td>415</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>265.1</td>\n",
       "      <td>110</td>\n",
       "      <td>45.07</td>\n",
       "      <td>197.4</td>\n",
       "      <td>99</td>\n",
       "      <td>16.78</td>\n",
       "      <td>244.7</td>\n",
       "      <td>91</td>\n",
       "      <td>11.01</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OH</td>\n",
       "      <td>107</td>\n",
       "      <td>415</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>161.6</td>\n",
       "      <td>123</td>\n",
       "      <td>27.47</td>\n",
       "      <td>195.5</td>\n",
       "      <td>103</td>\n",
       "      <td>16.62</td>\n",
       "      <td>254.4</td>\n",
       "      <td>103</td>\n",
       "      <td>11.45</td>\n",
       "      <td>13.7</td>\n",
       "      <td>3</td>\n",
       "      <td>3.70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NJ</td>\n",
       "      <td>137</td>\n",
       "      <td>415</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>243.4</td>\n",
       "      <td>114</td>\n",
       "      <td>41.38</td>\n",
       "      <td>121.2</td>\n",
       "      <td>110</td>\n",
       "      <td>10.30</td>\n",
       "      <td>162.6</td>\n",
       "      <td>104</td>\n",
       "      <td>7.32</td>\n",
       "      <td>12.2</td>\n",
       "      <td>5</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OH</td>\n",
       "      <td>84</td>\n",
       "      <td>408</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>299.4</td>\n",
       "      <td>71</td>\n",
       "      <td>50.90</td>\n",
       "      <td>61.9</td>\n",
       "      <td>88</td>\n",
       "      <td>5.26</td>\n",
       "      <td>196.9</td>\n",
       "      <td>89</td>\n",
       "      <td>8.86</td>\n",
       "      <td>6.6</td>\n",
       "      <td>7</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OK</td>\n",
       "      <td>75</td>\n",
       "      <td>415</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>166.7</td>\n",
       "      <td>113</td>\n",
       "      <td>28.34</td>\n",
       "      <td>148.3</td>\n",
       "      <td>122</td>\n",
       "      <td>12.61</td>\n",
       "      <td>186.9</td>\n",
       "      <td>121</td>\n",
       "      <td>8.41</td>\n",
       "      <td>10.1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.73</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  State  Account length  Area code  International plan  Voice mail plan  \\\n",
       "0    KS             128        415                   0                1   \n",
       "1    OH             107        415                   0                1   \n",
       "2    NJ             137        415                   0                0   \n",
       "3    OH              84        408                   1                0   \n",
       "4    OK              75        415                   1                0   \n",
       "\n",
       "   Number vmail messages  Total day minutes  Total day calls  \\\n",
       "0                     25              265.1              110   \n",
       "1                     26              161.6              123   \n",
       "2                      0              243.4              114   \n",
       "3                      0              299.4               71   \n",
       "4                      0              166.7              113   \n",
       "\n",
       "   Total day charge  Total eve minutes  Total eve calls  Total eve charge  \\\n",
       "0             45.07              197.4               99             16.78   \n",
       "1             27.47              195.5              103             16.62   \n",
       "2             41.38              121.2              110             10.30   \n",
       "3             50.90               61.9               88              5.26   \n",
       "4             28.34              148.3              122             12.61   \n",
       "\n",
       "   Total night minutes  Total night calls  Total night charge  \\\n",
       "0                244.7                 91               11.01   \n",
       "1                254.4                103               11.45   \n",
       "2                162.6                104                7.32   \n",
       "3                196.9                 89                8.86   \n",
       "4                186.9                121                8.41   \n",
       "\n",
       "   Total intl minutes  Total intl calls  Total intl charge  \\\n",
       "0                10.0                 3               2.70   \n",
       "1                13.7                 3               3.70   \n",
       "2                12.2                 5               3.29   \n",
       "3                 6.6                 7               1.78   \n",
       "4                10.1                 3               2.73   \n",
       "\n",
       "   Customer service calls  Churn  \n",
       "0                       1      0  \n",
       "1                       1      0  \n",
       "2                       0      0  \n",
       "3                       2      0  \n",
       "4                       3      0  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'Yes' : 1, 'No' : 0}\n",
    "df['International plan'] = df['International plan'].map(d)\n",
    "df['Voice mail plan'] = df['Voice mail plan'].map(d)\n",
    "df['Churn'] = df['Churn'].astype('int64')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide data to design matrix X and target vector y.\n",
    "\n",
    "Make a train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df=df.drop('State',axis=1)\n",
    "df.head()\n",
    "y=df['Churn']\n",
    "X=df.drop('Churn',axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2,\n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Account length</th>\n",
       "      <th>Area code</th>\n",
       "      <th>International plan</th>\n",
       "      <th>Voice mail plan</th>\n",
       "      <th>Number vmail messages</th>\n",
       "      <th>Total day minutes</th>\n",
       "      <th>Total day calls</th>\n",
       "      <th>Total day charge</th>\n",
       "      <th>Total eve minutes</th>\n",
       "      <th>Total eve calls</th>\n",
       "      <th>Total eve charge</th>\n",
       "      <th>Total night minutes</th>\n",
       "      <th>Total night calls</th>\n",
       "      <th>Total night charge</th>\n",
       "      <th>Total intl minutes</th>\n",
       "      <th>Total intl calls</th>\n",
       "      <th>Total intl charge</th>\n",
       "      <th>Customer service calls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3333.000000</td>\n",
       "      <td>3333.000000</td>\n",
       "      <td>3333.000000</td>\n",
       "      <td>3333.000000</td>\n",
       "      <td>3333.000000</td>\n",
       "      <td>3333.000000</td>\n",
       "      <td>3333.000000</td>\n",
       "      <td>3333.000000</td>\n",
       "      <td>3333.000000</td>\n",
       "      <td>3333.000000</td>\n",
       "      <td>3333.000000</td>\n",
       "      <td>3333.000000</td>\n",
       "      <td>3333.000000</td>\n",
       "      <td>3333.000000</td>\n",
       "      <td>3333.000000</td>\n",
       "      <td>3333.000000</td>\n",
       "      <td>3333.000000</td>\n",
       "      <td>3333.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>101.064806</td>\n",
       "      <td>437.182418</td>\n",
       "      <td>0.096910</td>\n",
       "      <td>0.276628</td>\n",
       "      <td>8.099010</td>\n",
       "      <td>179.775098</td>\n",
       "      <td>100.435644</td>\n",
       "      <td>30.562307</td>\n",
       "      <td>200.980348</td>\n",
       "      <td>100.114311</td>\n",
       "      <td>17.083540</td>\n",
       "      <td>200.872037</td>\n",
       "      <td>100.107711</td>\n",
       "      <td>9.039325</td>\n",
       "      <td>10.237294</td>\n",
       "      <td>4.479448</td>\n",
       "      <td>2.764581</td>\n",
       "      <td>1.562856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>39.822106</td>\n",
       "      <td>42.371290</td>\n",
       "      <td>0.295879</td>\n",
       "      <td>0.447398</td>\n",
       "      <td>13.688365</td>\n",
       "      <td>54.467389</td>\n",
       "      <td>20.069084</td>\n",
       "      <td>9.259435</td>\n",
       "      <td>50.713844</td>\n",
       "      <td>19.922625</td>\n",
       "      <td>4.310668</td>\n",
       "      <td>50.573847</td>\n",
       "      <td>19.568609</td>\n",
       "      <td>2.275873</td>\n",
       "      <td>2.791840</td>\n",
       "      <td>2.461214</td>\n",
       "      <td>0.753773</td>\n",
       "      <td>1.315491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>408.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.200000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>1.040000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>74.000000</td>\n",
       "      <td>408.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>143.700000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>24.430000</td>\n",
       "      <td>166.600000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>14.160000</td>\n",
       "      <td>167.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>7.520000</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>101.000000</td>\n",
       "      <td>415.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>179.400000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>201.400000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>17.120000</td>\n",
       "      <td>201.200000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>9.050000</td>\n",
       "      <td>10.300000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.780000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>127.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>216.400000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>36.790000</td>\n",
       "      <td>235.300000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>235.300000</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>10.590000</td>\n",
       "      <td>12.100000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.270000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>243.000000</td>\n",
       "      <td>510.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>350.800000</td>\n",
       "      <td>165.000000</td>\n",
       "      <td>59.640000</td>\n",
       "      <td>363.700000</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>30.910000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>17.770000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Account length    Area code  International plan  Voice mail plan  \\\n",
       "count     3333.000000  3333.000000         3333.000000      3333.000000   \n",
       "mean       101.064806   437.182418            0.096910         0.276628   \n",
       "std         39.822106    42.371290            0.295879         0.447398   \n",
       "min          1.000000   408.000000            0.000000         0.000000   \n",
       "25%         74.000000   408.000000            0.000000         0.000000   \n",
       "50%        101.000000   415.000000            0.000000         0.000000   \n",
       "75%        127.000000   510.000000            0.000000         1.000000   \n",
       "max        243.000000   510.000000            1.000000         1.000000   \n",
       "\n",
       "       Number vmail messages  Total day minutes  Total day calls  \\\n",
       "count            3333.000000        3333.000000      3333.000000   \n",
       "mean                8.099010         179.775098       100.435644   \n",
       "std                13.688365          54.467389        20.069084   \n",
       "min                 0.000000           0.000000         0.000000   \n",
       "25%                 0.000000         143.700000        87.000000   \n",
       "50%                 0.000000         179.400000       101.000000   \n",
       "75%                20.000000         216.400000       114.000000   \n",
       "max                51.000000         350.800000       165.000000   \n",
       "\n",
       "       Total day charge  Total eve minutes  Total eve calls  Total eve charge  \\\n",
       "count       3333.000000        3333.000000      3333.000000       3333.000000   \n",
       "mean          30.562307         200.980348       100.114311         17.083540   \n",
       "std            9.259435          50.713844        19.922625          4.310668   \n",
       "min            0.000000           0.000000         0.000000          0.000000   \n",
       "25%           24.430000         166.600000        87.000000         14.160000   \n",
       "50%           30.500000         201.400000       100.000000         17.120000   \n",
       "75%           36.790000         235.300000       114.000000         20.000000   \n",
       "max           59.640000         363.700000       170.000000         30.910000   \n",
       "\n",
       "       Total night minutes  Total night calls  Total night charge  \\\n",
       "count          3333.000000        3333.000000         3333.000000   \n",
       "mean            200.872037         100.107711            9.039325   \n",
       "std              50.573847          19.568609            2.275873   \n",
       "min              23.200000          33.000000            1.040000   \n",
       "25%             167.000000          87.000000            7.520000   \n",
       "50%             201.200000         100.000000            9.050000   \n",
       "75%             235.300000         113.000000           10.590000   \n",
       "max             395.000000         175.000000           17.770000   \n",
       "\n",
       "       Total intl minutes  Total intl calls  Total intl charge  \\\n",
       "count         3333.000000       3333.000000        3333.000000   \n",
       "mean            10.237294          4.479448           2.764581   \n",
       "std              2.791840          2.461214           0.753773   \n",
       "min              0.000000          0.000000           0.000000   \n",
       "25%              8.500000          3.000000           2.300000   \n",
       "50%             10.300000          4.000000           2.780000   \n",
       "75%             12.100000          6.000000           3.270000   \n",
       "max             20.000000         20.000000           5.400000   \n",
       "\n",
       "       Customer service calls  \n",
       "count             3333.000000  \n",
       "mean                 1.562856  \n",
       "std                  1.315491  \n",
       "min                  0.000000  \n",
       "25%                  1.000000  \n",
       "50%                  1.000000  \n",
       "75%                  2.000000  \n",
       "max                  9.000000  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Account length</th>\n",
       "      <th>International plan</th>\n",
       "      <th>Voice mail plan</th>\n",
       "      <th>Number vmail messages</th>\n",
       "      <th>Total day minutes</th>\n",
       "      <th>Total day calls</th>\n",
       "      <th>Total day charge</th>\n",
       "      <th>Total eve minutes</th>\n",
       "      <th>Total eve calls</th>\n",
       "      <th>Total eve charge</th>\n",
       "      <th>Total night minutes</th>\n",
       "      <th>Total night calls</th>\n",
       "      <th>Total night charge</th>\n",
       "      <th>Total intl minutes</th>\n",
       "      <th>Total intl calls</th>\n",
       "      <th>Total intl charge</th>\n",
       "      <th>Customer service calls</th>\n",
       "      <th>Area code_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KS</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>265.1</td>\n",
       "      <td>110</td>\n",
       "      <td>45.07</td>\n",
       "      <td>197.4</td>\n",
       "      <td>99</td>\n",
       "      <td>16.78</td>\n",
       "      <td>244.7</td>\n",
       "      <td>91</td>\n",
       "      <td>11.01</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1</td>\n",
       "      <td>415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OH</td>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>161.6</td>\n",
       "      <td>123</td>\n",
       "      <td>27.47</td>\n",
       "      <td>195.5</td>\n",
       "      <td>103</td>\n",
       "      <td>16.62</td>\n",
       "      <td>254.4</td>\n",
       "      <td>103</td>\n",
       "      <td>11.45</td>\n",
       "      <td>13.7</td>\n",
       "      <td>3</td>\n",
       "      <td>3.70</td>\n",
       "      <td>1</td>\n",
       "      <td>415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NJ</td>\n",
       "      <td>137</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>243.4</td>\n",
       "      <td>114</td>\n",
       "      <td>41.38</td>\n",
       "      <td>121.2</td>\n",
       "      <td>110</td>\n",
       "      <td>10.30</td>\n",
       "      <td>162.6</td>\n",
       "      <td>104</td>\n",
       "      <td>7.32</td>\n",
       "      <td>12.2</td>\n",
       "      <td>5</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0</td>\n",
       "      <td>415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OH</td>\n",
       "      <td>84</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>299.4</td>\n",
       "      <td>71</td>\n",
       "      <td>50.90</td>\n",
       "      <td>61.9</td>\n",
       "      <td>88</td>\n",
       "      <td>5.26</td>\n",
       "      <td>196.9</td>\n",
       "      <td>89</td>\n",
       "      <td>8.86</td>\n",
       "      <td>6.6</td>\n",
       "      <td>7</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2</td>\n",
       "      <td>408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OK</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>166.7</td>\n",
       "      <td>113</td>\n",
       "      <td>28.34</td>\n",
       "      <td>148.3</td>\n",
       "      <td>122</td>\n",
       "      <td>12.61</td>\n",
       "      <td>186.9</td>\n",
       "      <td>121</td>\n",
       "      <td>8.41</td>\n",
       "      <td>10.1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.73</td>\n",
       "      <td>3</td>\n",
       "      <td>415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  State  Account length  International plan  Voice mail plan  \\\n",
       "0    KS             128                   0                1   \n",
       "1    OH             107                   0                1   \n",
       "2    NJ             137                   0                0   \n",
       "3    OH              84                   1                0   \n",
       "4    OK              75                   1                0   \n",
       "\n",
       "   Number vmail messages  Total day minutes  Total day calls  \\\n",
       "0                     25              265.1              110   \n",
       "1                     26              161.6              123   \n",
       "2                      0              243.4              114   \n",
       "3                      0              299.4               71   \n",
       "4                      0              166.7              113   \n",
       "\n",
       "   Total day charge  Total eve minutes  Total eve calls  Total eve charge  \\\n",
       "0             45.07              197.4               99             16.78   \n",
       "1             27.47              195.5              103             16.62   \n",
       "2             41.38              121.2              110             10.30   \n",
       "3             50.90               61.9               88              5.26   \n",
       "4             28.34              148.3              122             12.61   \n",
       "\n",
       "   Total night minutes  Total night calls  Total night charge  \\\n",
       "0                244.7                 91               11.01   \n",
       "1                254.4                103               11.45   \n",
       "2                162.6                104                7.32   \n",
       "3                196.9                 89                8.86   \n",
       "4                186.9                121                8.41   \n",
       "\n",
       "   Total intl minutes  Total intl calls  Total intl charge  \\\n",
       "0                10.0                 3               2.70   \n",
       "1                13.7                 3               3.70   \n",
       "2                12.2                 5               3.29   \n",
       "3                 6.6                 7               1.78   \n",
       "4                10.1                 3               2.73   \n",
       "\n",
       "   Customer service calls Area code_cat  \n",
       "0                       1           415  \n",
       "1                       1           415  \n",
       "2                       0           415  \n",
       "3                       2           408  \n",
       "4                       3           415  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#<YOUR TURN>\n",
    "# analyse feature 'Area code' and transform it if nessesary\n",
    "#X['Area code'].unique()\n",
    "X['Area code_cat']=X['Area code'].astype(np.object)\n",
    "X=X.drop('Area code', axis=1)\n",
    "X.head()\n",
    "#X.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further we need to:\n",
    "- Impute missing numeric and categorical values.\n",
    "\n",
    "- Separate numerical and categorical fields.\n",
    "\n",
    "- Scale numerical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Account length</th>\n",
       "      <th>Area code</th>\n",
       "      <th>International plan</th>\n",
       "      <th>Voice mail plan</th>\n",
       "      <th>Number vmail messages</th>\n",
       "      <th>Total day minutes</th>\n",
       "      <th>Total day calls</th>\n",
       "      <th>Total day charge</th>\n",
       "      <th>Total eve minutes</th>\n",
       "      <th>Total eve calls</th>\n",
       "      <th>Total eve charge</th>\n",
       "      <th>Total night minutes</th>\n",
       "      <th>Total night calls</th>\n",
       "      <th>Total night charge</th>\n",
       "      <th>Total intl minutes</th>\n",
       "      <th>Total intl calls</th>\n",
       "      <th>Total intl charge</th>\n",
       "      <th>Customer service calls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1460</th>\n",
       "      <td>MT</td>\n",
       "      <td>80</td>\n",
       "      <td>415</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>198.1</td>\n",
       "      <td>160</td>\n",
       "      <td>33.68</td>\n",
       "      <td>156.7</td>\n",
       "      <td>87</td>\n",
       "      <td>13.32</td>\n",
       "      <td>182.1</td>\n",
       "      <td>76</td>\n",
       "      <td>8.19</td>\n",
       "      <td>9.3</td>\n",
       "      <td>3</td>\n",
       "      <td>2.51</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>PA</td>\n",
       "      <td>28</td>\n",
       "      <td>415</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>168.2</td>\n",
       "      <td>87</td>\n",
       "      <td>28.59</td>\n",
       "      <td>161.7</td>\n",
       "      <td>92</td>\n",
       "      <td>13.74</td>\n",
       "      <td>192.4</td>\n",
       "      <td>112</td>\n",
       "      <td>8.66</td>\n",
       "      <td>10.1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.73</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>OR</td>\n",
       "      <td>120</td>\n",
       "      <td>415</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>120</td>\n",
       "      <td>42.84</td>\n",
       "      <td>150.2</td>\n",
       "      <td>106</td>\n",
       "      <td>12.77</td>\n",
       "      <td>151.8</td>\n",
       "      <td>96</td>\n",
       "      <td>6.83</td>\n",
       "      <td>9.6</td>\n",
       "      <td>1</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2962</th>\n",
       "      <td>SD</td>\n",
       "      <td>105</td>\n",
       "      <td>415</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>251.6</td>\n",
       "      <td>88</td>\n",
       "      <td>42.77</td>\n",
       "      <td>175.1</td>\n",
       "      <td>103</td>\n",
       "      <td>14.88</td>\n",
       "      <td>184.4</td>\n",
       "      <td>112</td>\n",
       "      <td>8.30</td>\n",
       "      <td>5.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1.46</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2773</th>\n",
       "      <td>NJ</td>\n",
       "      <td>134</td>\n",
       "      <td>510</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>247.2</td>\n",
       "      <td>105</td>\n",
       "      <td>42.02</td>\n",
       "      <td>225.5</td>\n",
       "      <td>133</td>\n",
       "      <td>19.17</td>\n",
       "      <td>186.3</td>\n",
       "      <td>76</td>\n",
       "      <td>8.38</td>\n",
       "      <td>6.1</td>\n",
       "      <td>5</td>\n",
       "      <td>1.65</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     State  Account length  Area code  International plan  Voice mail plan  \\\n",
       "1460    MT              80        415                   0                0   \n",
       "2000    PA              28        415                   0                0   \n",
       "666     OR             120        415                   0                0   \n",
       "2962    SD             105        415                   0                0   \n",
       "2773    NJ             134        510                   0                1   \n",
       "\n",
       "      Number vmail messages  Total day minutes  Total day calls  \\\n",
       "1460                      0              198.1              160   \n",
       "2000                      0              168.2               87   \n",
       "666                       0              252.0              120   \n",
       "2962                      0              251.6               88   \n",
       "2773                     34              247.2              105   \n",
       "\n",
       "      Total day charge  Total eve minutes  Total eve calls  Total eve charge  \\\n",
       "1460             33.68              156.7               87             13.32   \n",
       "2000             28.59              161.7               92             13.74   \n",
       "666              42.84              150.2              106             12.77   \n",
       "2962             42.77              175.1              103             14.88   \n",
       "2773             42.02              225.5              133             19.17   \n",
       "\n",
       "      Total night minutes  Total night calls  Total night charge  \\\n",
       "1460                182.1                 76                8.19   \n",
       "2000                192.4                112                8.66   \n",
       "666                 151.8                 96                6.83   \n",
       "2962                184.4                112                8.30   \n",
       "2773                186.3                 76                8.38   \n",
       "\n",
       "      Total intl minutes  Total intl calls  Total intl charge  \\\n",
       "1460                 9.3                 3               2.51   \n",
       "2000                10.1                 3               2.73   \n",
       "666                  9.6                 1               2.59   \n",
       "2962                 5.4                 5               1.46   \n",
       "2773                 6.1                 5               1.65   \n",
       "\n",
       "      Customer service calls  \n",
       "1460                       3  \n",
       "2000                       3  \n",
       "666                        2  \n",
       "2962                       1  \n",
       "2773                       2  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "numeric_data = X_train.select_dtypes([np.number])\n",
    "numeric_data_mean = numeric_data.mean()\n",
    "X_train = X_train.fillna(numeric_data_mean)\n",
    "X_test = X_test.fillna(numeric_data_mean)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we don't extract all the information from the data, simply because we do not use some of the features. These features in the dataset are encoded in strings, each of them represents a certain category. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first fill in missing categorical features with special category \"NotGiven\". Sometimes the fact that a feature has a missing value can be a good sign itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = numeric_data.columns\n",
    "categorical = list(X_train.dtypes[X_train.dtypes == \"object\"].index)\n",
    "X_train[categorical] = X_train[categorical].fillna(\"NotGiven\")\n",
    "X_test[categorical] = X_test[categorical].fillna(\"NotGiven\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Account length</th>\n",
       "      <th>Area code</th>\n",
       "      <th>International plan</th>\n",
       "      <th>Voice mail plan</th>\n",
       "      <th>Number vmail messages</th>\n",
       "      <th>Total day minutes</th>\n",
       "      <th>Total day calls</th>\n",
       "      <th>Total day charge</th>\n",
       "      <th>Total eve minutes</th>\n",
       "      <th>Total eve calls</th>\n",
       "      <th>Total eve charge</th>\n",
       "      <th>Total night minutes</th>\n",
       "      <th>Total night calls</th>\n",
       "      <th>Total night charge</th>\n",
       "      <th>Total intl minutes</th>\n",
       "      <th>Total intl calls</th>\n",
       "      <th>Total intl charge</th>\n",
       "      <th>Customer service calls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1460</th>\n",
       "      <td>MT</td>\n",
       "      <td>80</td>\n",
       "      <td>415</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>198.1</td>\n",
       "      <td>160</td>\n",
       "      <td>33.68</td>\n",
       "      <td>156.7</td>\n",
       "      <td>87</td>\n",
       "      <td>13.32</td>\n",
       "      <td>182.1</td>\n",
       "      <td>76</td>\n",
       "      <td>8.19</td>\n",
       "      <td>9.3</td>\n",
       "      <td>3</td>\n",
       "      <td>2.51</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>PA</td>\n",
       "      <td>28</td>\n",
       "      <td>415</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>168.2</td>\n",
       "      <td>87</td>\n",
       "      <td>28.59</td>\n",
       "      <td>161.7</td>\n",
       "      <td>92</td>\n",
       "      <td>13.74</td>\n",
       "      <td>192.4</td>\n",
       "      <td>112</td>\n",
       "      <td>8.66</td>\n",
       "      <td>10.1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.73</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>OR</td>\n",
       "      <td>120</td>\n",
       "      <td>415</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>120</td>\n",
       "      <td>42.84</td>\n",
       "      <td>150.2</td>\n",
       "      <td>106</td>\n",
       "      <td>12.77</td>\n",
       "      <td>151.8</td>\n",
       "      <td>96</td>\n",
       "      <td>6.83</td>\n",
       "      <td>9.6</td>\n",
       "      <td>1</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2962</th>\n",
       "      <td>SD</td>\n",
       "      <td>105</td>\n",
       "      <td>415</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>251.6</td>\n",
       "      <td>88</td>\n",
       "      <td>42.77</td>\n",
       "      <td>175.1</td>\n",
       "      <td>103</td>\n",
       "      <td>14.88</td>\n",
       "      <td>184.4</td>\n",
       "      <td>112</td>\n",
       "      <td>8.30</td>\n",
       "      <td>5.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1.46</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2773</th>\n",
       "      <td>NJ</td>\n",
       "      <td>134</td>\n",
       "      <td>510</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>247.2</td>\n",
       "      <td>105</td>\n",
       "      <td>42.02</td>\n",
       "      <td>225.5</td>\n",
       "      <td>133</td>\n",
       "      <td>19.17</td>\n",
       "      <td>186.3</td>\n",
       "      <td>76</td>\n",
       "      <td>8.38</td>\n",
       "      <td>6.1</td>\n",
       "      <td>5</td>\n",
       "      <td>1.65</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     State  Account length  Area code  International plan  Voice mail plan  \\\n",
       "1460    MT              80        415                   0                0   \n",
       "2000    PA              28        415                   0                0   \n",
       "666     OR             120        415                   0                0   \n",
       "2962    SD             105        415                   0                0   \n",
       "2773    NJ             134        510                   0                1   \n",
       "\n",
       "      Number vmail messages  Total day minutes  Total day calls  \\\n",
       "1460                      0              198.1              160   \n",
       "2000                      0              168.2               87   \n",
       "666                       0              252.0              120   \n",
       "2962                      0              251.6               88   \n",
       "2773                     34              247.2              105   \n",
       "\n",
       "      Total day charge  Total eve minutes  Total eve calls  Total eve charge  \\\n",
       "1460             33.68              156.7               87             13.32   \n",
       "2000             28.59              161.7               92             13.74   \n",
       "666              42.84              150.2              106             12.77   \n",
       "2962             42.77              175.1              103             14.88   \n",
       "2773             42.02              225.5              133             19.17   \n",
       "\n",
       "      Total night minutes  Total night calls  Total night charge  \\\n",
       "1460                182.1                 76                8.19   \n",
       "2000                192.4                112                8.66   \n",
       "666                 151.8                 96                6.83   \n",
       "2962                184.4                112                8.30   \n",
       "2773                186.3                 76                8.38   \n",
       "\n",
       "      Total intl minutes  Total intl calls  Total intl charge  \\\n",
       "1460                 9.3                 3               2.51   \n",
       "2000                10.1                 3               2.73   \n",
       "666                  9.6                 1               2.59   \n",
       "2962                 5.4                 5               1.46   \n",
       "2773                 6.1                 5               1.65   \n",
       "\n",
       "      Customer service calls  \n",
       "1460                       3  \n",
       "2000                       3  \n",
       "666                        2  \n",
       "2962                       1  \n",
       "2773                       2  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical features encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many ML algorithms do not work with categorial features and assume only numeric. If you want to transform categorial features into numeric, you may use encoding.  Two standard transformers from sklearn for working with categorical features are `OrdinalEncoder` (simply renumbers feature values with natural numbers) and `OneHotEncoder` (dummy features)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://russianblogs.com/images/855/ddd65f4f342886bb411d41a33c5528e7.png\" width=50%> \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `OneHotEncoder` is a representation of categorical variables as binary vectors.\n",
    "\n",
    "`OneHotEncoder` assigns to each feature a whole vector consisting of zeros and one unit (which stands in the place corresponding to the received value, thus encoding it).\n",
    "\n",
    "Then, each integer value is represented as a binary vector that is all zero values except the index of the integer, which is marked with a 1.\n",
    "\n",
    "Is it worth to apply a scaling transformer to features encoded by `OneHotEncoder`?\n",
    "What's about applying  `OrdinalEncoder` in the case of a linear model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can write more streamlined  code with Pipeline:\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/620/1*ONryJuHGGUZ6PUmYTMiFxQ.png\" width=50%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model training is often presented as a sequence of some actions with training and test sets (for example, you first need to scale the sample (and for the training set you need to apply the fit method, and for the test set - transform), and then train/apply the model (for the train sample fit, and make predictions for test sample)  \n",
    "\n",
    "The `sklearn.pipeline.Pipeline` class allows you to store this sequence of steps and correctly applies it to both training and test samples.\n",
    "\n",
    "sklearn also has a class to make a pipeline without naming: `sklearn.pipeline.make_pipeline` \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ColumnTransformer\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/537/1*BNwN3cmbLLoU9CQoJgFSKQ.png\" width=30%> \n",
    "\n",
    "\n",
    "We often need to apply different sets of tranformers to different groups of columns. For instance, we would want to apply OneHotEncoder to only categorical columns but not to numerical columns. This is where ColumnTransformer comes in. This time, we will partition the dataset keeping all columns so that we have both numerical and categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.879648</td>\n",
       "      <td>-0.653460</td>\n",
       "      <td>-0.879573</td>\n",
       "      <td>-0.377791</td>\n",
       "      <td>-1.214353</td>\n",
       "      <td>-0.379791</td>\n",
       "      <td>-0.334364</td>\n",
       "      <td>-0.605667</td>\n",
       "      <td>-0.336336</td>\n",
       "      <td>1.097125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.781652</td>\n",
       "      <td>-0.403801</td>\n",
       "      <td>-0.782731</td>\n",
       "      <td>-0.174258</td>\n",
       "      <td>0.602831</td>\n",
       "      <td>-0.173408</td>\n",
       "      <td>-0.049965</td>\n",
       "      <td>-0.605667</td>\n",
       "      <td>-0.046662</td>\n",
       "      <td>1.097125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.007043</td>\n",
       "      <td>0.295246</td>\n",
       "      <td>-1.006391</td>\n",
       "      <td>-0.976535</td>\n",
       "      <td>-0.204806</td>\n",
       "      <td>-0.976985</td>\n",
       "      <td>-0.227714</td>\n",
       "      <td>-1.425524</td>\n",
       "      <td>-0.231000</td>\n",
       "      <td>0.338190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.519022</td>\n",
       "      <td>0.145451</td>\n",
       "      <td>-0.519873</td>\n",
       "      <td>-0.332342</td>\n",
       "      <td>0.602831</td>\n",
       "      <td>-0.331489</td>\n",
       "      <td>-1.720811</td>\n",
       "      <td>0.214190</td>\n",
       "      <td>-1.718868</td>\n",
       "      <td>-0.420745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.468778</td>\n",
       "      <td>1.643408</td>\n",
       "      <td>0.469303</td>\n",
       "      <td>-0.294797</td>\n",
       "      <td>-1.214353</td>\n",
       "      <td>-0.296360</td>\n",
       "      <td>-1.471962</td>\n",
       "      <td>0.214190</td>\n",
       "      <td>-1.468696</td>\n",
       "      <td>0.338190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1    2    3    4    5    6    7    8    9   ...        59        60  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ... -0.879648 -0.653460   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ... -0.781652 -0.403801   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ... -1.007043  0.295246   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ... -0.519022  0.145451   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.468778  1.643408   \n",
       "\n",
       "         61        62        63        64        65        66        67  \\\n",
       "0 -0.879573 -0.377791 -1.214353 -0.379791 -0.334364 -0.605667 -0.336336   \n",
       "1 -0.782731 -0.174258  0.602831 -0.173408 -0.049965 -0.605667 -0.046662   \n",
       "2 -1.006391 -0.976535 -0.204806 -0.976985 -0.227714 -1.425524 -0.231000   \n",
       "3 -0.519873 -0.332342  0.602831 -0.331489 -1.720811  0.214190 -1.718868   \n",
       "4  0.469303 -0.294797 -1.214353 -0.296360 -1.471962  0.214190 -1.468696   \n",
       "\n",
       "         68  \n",
       "0  1.097125  \n",
       "1  1.097125  \n",
       "2  0.338190  \n",
       "3 -0.420745  \n",
       "4  0.338190  \n",
       "\n",
       "[5 rows x 69 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegressionCV,LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "\n",
    "column_transformer = ColumnTransformer([\n",
    "    ('ohe', OneHotEncoder(handle_unknown=\"ignore\",sparse=False), categorical),\n",
    "    ('scaling', StandardScaler(), numeric_features)\n",
    "])\n",
    "X_train_encoded=column_transformer.fit_transform(X_train)\n",
    "\n",
    "pd.DataFrame(X_train_encoded).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've got 2 realizations of LogisticRegression:\n",
    "\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "\n",
    "\n",
    "- class sklearn.linear_model.LogisticRegression ()\n",
    "- class sklearn.linear_model.LogisticRegressionCV(*,\n",
    "\n",
    "                     Cs=10, fit_intercept=True, cv=None, dual=False, penalty='l2',\n",
    "                     \n",
    "                     scoring=None,  solver='lbfgs', tol=0.0001, max_iter=100,\n",
    "                     \n",
    "                     class_weight=None, n_jobs=None, verbose=0, refit=True, \n",
    "                     \n",
    "                     intercept_scaling=1.0, multi_class='auto', random_state=None, l1_ratios=None)\n",
    "                     \n",
    "   - Cs - Inverse of regularization strength; must be a positive float. Like in support vector machines, smaller values specify stronger regularization.\n",
    "   - penalty -{‘l1’, ‘l2’, ‘elasticnet’, ‘none’}, default=’l2’\n",
    "   - solver{‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’, ‘saga’}, default=’lbfgs’. Algorithm to use in the optimization problem. Default is ‘lbfgs’. \n",
    "\n",
    "   - cv : cvint or cross-validation generator, default=None\n",
    "            The default cross-validation generator(for example,KFold or LeaveOneOut)  used is Stratified K-Folds. If an integer is provided, then it is the number of folds used. \n",
    "   - l1_ratioslist of float, default=None. The list of Elastic-Net mixing parameter\n",
    "   \n",
    "In addition to the standard `fit`,`predict` methods, the `predict_proba()` method is useful for classifiers  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Let's create a logistic regression with L2-regularization in Pipeline with feature transformation, find the best parameters on cross-validation on the grid of the regularization parameter С: [0.0001,0.001,0.01,0.1,1,10,100].\n",
    "We'll use the LogisticRegressionCV and the number of cross-validation blocks cv=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0\n",
      "0  0.275120\n",
      "1  0.014655\n",
      "2  0.223863\n",
      "3  0.054590\n",
      "4  0.883605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#import warnings\n",
    "#warnings.simplefilter(\"ignore\")\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('ohe_and_scaling', column_transformer),\n",
    "    ('regression', LogisticRegressionCV(penalty='l2',Cs=[0.0001,0.001,0.01,0.1,1,10,100],\n",
    "                                        cv=5,refit=True))\n",
    "])\n",
    "\n",
    "model = pipeline.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "y_proba = model.predict_proba(X_test)\n",
    "print(pd.DataFrame(y_proba[:, 1]).head())\n",
    "#print(pd.DataFrame(y_proba).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Test accuracy = 0.8396\n",
      "2. C = 100.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(\"1. Test accuracy = %.4f\" % accuracy_score(y_pred,y_test))\n",
    "print(\"2. C = %.4f\" % model['regression'].C_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<YOUR TURN>\n",
    "#try to use here GridSearchCV and LogisticRegression  instead of LogisticRegressionCV.\n",
    "#did you get the same accuracy result?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature binarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "For feature binarization, you can use the class `sklearn.preprocessing.KBinsDiscretizer`:\n",
    "sklearn.preprocessing.KBinsDiscretizer(n_bins=5, *, encode='onehot', strategy='quantile', dtype=None)\n",
    "\n",
    "       strategy(default=’quantile’):\n",
    "            - uniform - \n",
    "            - quantile -  \n",
    "            - kmeans - 1D k-means cluster.\n",
    "            - encode: 'ordinal'\n",
    "Advantages of binarization: capturing non-monotonic and non-linear dependences feature from the target.\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Instead of `StandardScaler`, we apply the class method `sklearn.preprocessing.KBinsDiscretizer` to numerical features with splitting into 25 groups and splitting strategy 'kmeans' to numerical features.\n",
    "At the same time we apply `OneHotEncoder` to categorical features.\n",
    "We use `ColumnTransformer` to combine uniformely these 2 transformation for the train and test datasets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import KBinsDiscretizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:200: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 1 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn('Bins whose width are too small (i.e., <= '\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:200: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 2 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn('Bins whose width are too small (i.e., <= '\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:200: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 3 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn('Bins whose width are too small (i.e., <= '\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:200: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 4 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn('Bins whose width are too small (i.e., <= '\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:200: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 15 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn('Bins whose width are too small (i.e., <= '\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_discretization.py:200: UserWarning: Bins whose width are too small (i.e., <= 1e-8) in feature 17 are removed. Consider decreasing the number of bins.\n",
      "  warnings.warn('Bins whose width are too small (i.e., <= '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy = 0.8771\n",
      "C= 0.1000\n",
      "Wall time: 3.07 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "column_transformer = ColumnTransformer([\n",
    "    ('ohe', OneHotEncoder(handle_unknown=\"ignore\"), categorical),\n",
    "    ('binner',  KBinsDiscretizer(n_bins=25, strategy='quantile'), numeric_features)\n",
    "])\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('ohe_and_scaling', column_transformer),\n",
    "    ('regression',  LogisticRegressionCV(penalty='l2',Cs=[0.0001,0.001,0.01,0.1,1,10,100],cv=5,max_iter=1000,\n",
    "                                       random_state=random_state))\n",
    "])\n",
    "\n",
    "model = pipeline.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Test accuracy = %.4f\" % accuracy_score(y_pred,y_test))\n",
    "print(\"C= %.4f\" % model[1].C_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solver='liblinear'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#you turn \n",
    "#apply polinomial features instead of Kbindiskretizer and calculate accuracy\n",
    "#compare time of running (use magic %%time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy = 0.8861\n",
      "C= 0.0001\n",
      "Wall time: 12min 54s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "\n",
    "\n",
    "column_transformer = ColumnTransformer([\n",
    "    ('ohe', OneHotEncoder(handle_unknown=\"ignore\"), categorical),\n",
    "    ('binner',   PolynomialFeatures(2), numeric_features)\n",
    "])\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('ohe_and_scaling', column_transformer),\n",
    "    ('regression',  LogisticRegressionCV(penalty='l1',Cs=[0.0001,0.001,0.01,0.1,1,10,100],cv=5,solver='saga',max_iter=1000,\n",
    "                                       random_state=random_state))\n",
    "])\n",
    "\n",
    "model = pipeline.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Test accuracy = %.4f\" % accuracy_score(y_pred,y_test))\n",
    "print(\"C= %.4f\" % model[1].C_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization of quantile binaization of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Account length</th>\n",
       "      <th>Area code</th>\n",
       "      <th>International plan</th>\n",
       "      <th>Voice mail plan</th>\n",
       "      <th>Number vmail messages</th>\n",
       "      <th>Total day minutes</th>\n",
       "      <th>Total day calls</th>\n",
       "      <th>Total day charge</th>\n",
       "      <th>Total eve minutes</th>\n",
       "      <th>...</th>\n",
       "      <th>Total night calls</th>\n",
       "      <th>Total night charge</th>\n",
       "      <th>Total intl minutes</th>\n",
       "      <th>Total intl calls</th>\n",
       "      <th>Total intl charge</th>\n",
       "      <th>Customer service calls</th>\n",
       "      <th>Churn</th>\n",
       "      <th>q_minutes</th>\n",
       "      <th>service_calls</th>\n",
       "      <th>share</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KS</td>\n",
       "      <td>128</td>\n",
       "      <td>415</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>265.1</td>\n",
       "      <td>110</td>\n",
       "      <td>45.07</td>\n",
       "      <td>197.4</td>\n",
       "      <td>...</td>\n",
       "      <td>91</td>\n",
       "      <td>11.01</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>(9.4, 10.0]</td>\n",
       "      <td>(-0.009, 1.8]</td>\n",
       "      <td>(0.051, 0.062]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OH</td>\n",
       "      <td>107</td>\n",
       "      <td>415</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>161.6</td>\n",
       "      <td>123</td>\n",
       "      <td>27.47</td>\n",
       "      <td>195.5</td>\n",
       "      <td>...</td>\n",
       "      <td>103</td>\n",
       "      <td>11.45</td>\n",
       "      <td>13.7</td>\n",
       "      <td>3</td>\n",
       "      <td>3.70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>(12.7, 13.8]</td>\n",
       "      <td>(-0.009, 1.8]</td>\n",
       "      <td>(0.13, 0.17]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NJ</td>\n",
       "      <td>137</td>\n",
       "      <td>415</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>243.4</td>\n",
       "      <td>114</td>\n",
       "      <td>41.38</td>\n",
       "      <td>121.2</td>\n",
       "      <td>...</td>\n",
       "      <td>104</td>\n",
       "      <td>7.32</td>\n",
       "      <td>12.2</td>\n",
       "      <td>5</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(11.9, 12.7]</td>\n",
       "      <td>(-0.009, 1.8]</td>\n",
       "      <td>(0.079, 0.087]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OH</td>\n",
       "      <td>84</td>\n",
       "      <td>408</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>299.4</td>\n",
       "      <td>71</td>\n",
       "      <td>50.90</td>\n",
       "      <td>61.9</td>\n",
       "      <td>...</td>\n",
       "      <td>89</td>\n",
       "      <td>8.86</td>\n",
       "      <td>6.6</td>\n",
       "      <td>7</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>(6.5, 7.8]</td>\n",
       "      <td>(1.8, 3.6]</td>\n",
       "      <td>(-0.01, 0.051]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OK</td>\n",
       "      <td>75</td>\n",
       "      <td>415</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>166.7</td>\n",
       "      <td>113</td>\n",
       "      <td>28.34</td>\n",
       "      <td>148.3</td>\n",
       "      <td>...</td>\n",
       "      <td>121</td>\n",
       "      <td>8.41</td>\n",
       "      <td>10.1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.73</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>(10.0, 10.6]</td>\n",
       "      <td>(1.8, 3.6]</td>\n",
       "      <td>(0.095, 0.1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AL</td>\n",
       "      <td>118</td>\n",
       "      <td>510</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>223.4</td>\n",
       "      <td>98</td>\n",
       "      <td>37.98</td>\n",
       "      <td>220.6</td>\n",
       "      <td>...</td>\n",
       "      <td>118</td>\n",
       "      <td>9.18</td>\n",
       "      <td>6.3</td>\n",
       "      <td>6</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(-0.001, 6.5]</td>\n",
       "      <td>(-0.009, 1.8]</td>\n",
       "      <td>(-0.01, 0.051]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MA</td>\n",
       "      <td>121</td>\n",
       "      <td>510</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>218.2</td>\n",
       "      <td>88</td>\n",
       "      <td>37.09</td>\n",
       "      <td>348.5</td>\n",
       "      <td>...</td>\n",
       "      <td>118</td>\n",
       "      <td>9.57</td>\n",
       "      <td>7.5</td>\n",
       "      <td>7</td>\n",
       "      <td>2.03</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>(6.5, 7.8]</td>\n",
       "      <td>(1.8, 3.6]</td>\n",
       "      <td>(0.051, 0.062]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MO</td>\n",
       "      <td>147</td>\n",
       "      <td>415</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>79</td>\n",
       "      <td>26.69</td>\n",
       "      <td>103.1</td>\n",
       "      <td>...</td>\n",
       "      <td>96</td>\n",
       "      <td>9.53</td>\n",
       "      <td>7.1</td>\n",
       "      <td>6</td>\n",
       "      <td>1.92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(6.5, 7.8]</td>\n",
       "      <td>(-0.009, 1.8]</td>\n",
       "      <td>(0.071, 0.079]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LA</td>\n",
       "      <td>117</td>\n",
       "      <td>408</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>184.5</td>\n",
       "      <td>97</td>\n",
       "      <td>31.37</td>\n",
       "      <td>351.6</td>\n",
       "      <td>...</td>\n",
       "      <td>90</td>\n",
       "      <td>9.71</td>\n",
       "      <td>8.7</td>\n",
       "      <td>4</td>\n",
       "      <td>2.35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>(7.8, 8.7]</td>\n",
       "      <td>(-0.009, 1.8]</td>\n",
       "      <td>(0.071, 0.079]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>WV</td>\n",
       "      <td>141</td>\n",
       "      <td>415</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>258.6</td>\n",
       "      <td>84</td>\n",
       "      <td>43.96</td>\n",
       "      <td>222.0</td>\n",
       "      <td>...</td>\n",
       "      <td>97</td>\n",
       "      <td>14.69</td>\n",
       "      <td>11.2</td>\n",
       "      <td>5</td>\n",
       "      <td>3.02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(10.6, 11.2]</td>\n",
       "      <td>(-0.009, 1.8]</td>\n",
       "      <td>(0.062, 0.071]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  State  Account length  Area code  International plan  Voice mail plan  \\\n",
       "0    KS             128        415                   0                1   \n",
       "1    OH             107        415                   0                1   \n",
       "2    NJ             137        415                   0                0   \n",
       "3    OH              84        408                   1                0   \n",
       "4    OK              75        415                   1                0   \n",
       "5    AL             118        510                   1                0   \n",
       "6    MA             121        510                   0                1   \n",
       "7    MO             147        415                   1                0   \n",
       "8    LA             117        408                   0                0   \n",
       "9    WV             141        415                   1                1   \n",
       "\n",
       "   Number vmail messages  Total day minutes  Total day calls  \\\n",
       "0                     25              265.1              110   \n",
       "1                     26              161.6              123   \n",
       "2                      0              243.4              114   \n",
       "3                      0              299.4               71   \n",
       "4                      0              166.7              113   \n",
       "5                      0              223.4               98   \n",
       "6                     24              218.2               88   \n",
       "7                      0              157.0               79   \n",
       "8                      0              184.5               97   \n",
       "9                     37              258.6               84   \n",
       "\n",
       "   Total day charge  Total eve minutes  ...  Total night calls  \\\n",
       "0             45.07              197.4  ...                 91   \n",
       "1             27.47              195.5  ...                103   \n",
       "2             41.38              121.2  ...                104   \n",
       "3             50.90               61.9  ...                 89   \n",
       "4             28.34              148.3  ...                121   \n",
       "5             37.98              220.6  ...                118   \n",
       "6             37.09              348.5  ...                118   \n",
       "7             26.69              103.1  ...                 96   \n",
       "8             31.37              351.6  ...                 90   \n",
       "9             43.96              222.0  ...                 97   \n",
       "\n",
       "   Total night charge  Total intl minutes  Total intl calls  \\\n",
       "0               11.01                10.0                 3   \n",
       "1               11.45                13.7                 3   \n",
       "2                7.32                12.2                 5   \n",
       "3                8.86                 6.6                 7   \n",
       "4                8.41                10.1                 3   \n",
       "5                9.18                 6.3                 6   \n",
       "6                9.57                 7.5                 7   \n",
       "7                9.53                 7.1                 6   \n",
       "8                9.71                 8.7                 4   \n",
       "9               14.69                11.2                 5   \n",
       "\n",
       "   Total intl charge  Customer service calls  Churn      q_minutes  \\\n",
       "0               2.70                       1      0    (9.4, 10.0]   \n",
       "1               3.70                       1      0   (12.7, 13.8]   \n",
       "2               3.29                       0      0   (11.9, 12.7]   \n",
       "3               1.78                       2      0     (6.5, 7.8]   \n",
       "4               2.73                       3      0   (10.0, 10.6]   \n",
       "5               1.70                       0      0  (-0.001, 6.5]   \n",
       "6               2.03                       3      0     (6.5, 7.8]   \n",
       "7               1.92                       0      0     (6.5, 7.8]   \n",
       "8               2.35                       1      0     (7.8, 8.7]   \n",
       "9               3.02                       0      0   (10.6, 11.2]   \n",
       "\n",
       "   service_calls           share  \n",
       "0  (-0.009, 1.8]  (0.051, 0.062]  \n",
       "1  (-0.009, 1.8]    (0.13, 0.17]  \n",
       "2  (-0.009, 1.8]  (0.079, 0.087]  \n",
       "3     (1.8, 3.6]  (-0.01, 0.051]  \n",
       "4     (1.8, 3.6]    (0.095, 0.1]  \n",
       "5  (-0.009, 1.8]  (-0.01, 0.051]  \n",
       "6     (1.8, 3.6]  (0.051, 0.062]  \n",
       "7  (-0.009, 1.8]  (0.071, 0.079]  \n",
       "8  (-0.009, 1.8]  (0.071, 0.079]  \n",
       "9  (-0.009, 1.8]  (0.062, 0.071]  \n",
       "\n",
       "[10 rows x 23 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "df['q_minutes'] = pd.qcut(df['Total intl minutes'], 11)\n",
    "df['service_calls'] = pd.cut(df['Customer service calls'], 5)\n",
    "df['share'] = pd.qcut(df['Total intl charge']/df['Total day charge'],11,precision=2)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, \"'Total intl minutes'\")"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "sns.barplot(x= 'service_calls',y='Churn',data=df,color=\"blue\",saturation=0.25)\n",
    "plt.xlabel(\"'Total intl minutes'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Total intl minutes')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0YAAAE9CAYAAAAvXnIzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dfbRtZV0v8O/Pc0QS9WoCYgKBRnkp0epIpplivqFd0aEVZr5wJQZdzfAO49rt3jTvdZR4R5ZDjRgGZjejUUmdFN9G4ksKVw6JvCWKSHLAg/iSihZ09Ll/rLlhsVlr77X2XnPvc878fMZYY6015/PM+du/Pfde67fms55ZrbUAAAAM2d02OwAAAIDNpjACAAAGT2EEAAAMnsIIAAAYPIURAAAweAojAABg8LZudgCLdOCBB7Yjjjhis8MAAAD2UJdccsmXW2sHLV++TxVGRxxxRHbs2LHZYQAAAHuoqvrnScsNpQMAAAZPYQQAAAyewggAABg8hREAADB4CiMAAGDwFEYAAMDgKYwAAIDBUxgBAACDpzACAAAGT2EEAAAM3tbNDmBfdPrpp2fXrl055JBDcsYZZ2x2OHsUuQEAYE+kMOrBrl27csMNN2x2GHskuQEAYE9kKB0AADB4CiMAAGDwFEYAAMDgKYwAAIDBUxgBAACDpzACAAAGT2EEAAAMnsIIAAAYPIURAAAweAojAABg8BRGAADA4CmMAACAwVMYAQAAg6cwAgAABk9hBAAADF6vhVFVPbWqrq6qa6rqlRPWP6+qLutuH6+qh4+tu66qLq+qS6tqR59xAgAAw7a1rw1X1ZYkb07ypCQ7k1xcVdtba1eNNft8kse11r5WVccnOSvJT4ytP6619uW+YgQAAEj6PWN0bJJrWmvXttZuS3JukhPGG7TWPt5a+1r39KIkh/YYDwAAwER9FkYPSnL92POd3bJpXpzkPWPPW5L3V9UlVXVKD/EBAAAk6XEoXZKasKxNbFh1XEaF0U+NLX5Ma+3Gqjo4yQeq6tOttY9M6HtKklOS5PDDD19/1AAAwOD0ecZoZ5LDxp4fmuTG5Y2q6pgkb01yQmvtK0vLW2s3dvdfSnJeRkPz7qK1dlZrbVtrbdtBBx20wPABAICh6LMwujjJUVV1ZFXtl+TEJNvHG1TV4UnemeT5rbXPjC0/oKruvfQ4yZOTXNFjrAAAwID1NpSutba7ql6a5H1JtiQ5u7V2ZVWd2q0/M8lvJbl/krdUVZLsbq1tS/KAJOd1y7YmeUdr7b19xQoAAAxbn98xSmvt/CTnL1t25tjjk5OcPKHftUkevnw5AABAH3q9wCsAAMDeQGEEAAAMnsIIAAAYPIURAAAweAojAABg8BRGAADA4CmMAACAwVMYAQAAg6cwAgAABk9hBAAADJ7CCAAAGDyFEQAAMHgKIwAAYPAURgAAwOApjAAAgMFTGAEAAIO3dbMDYPOddNLbNmxfN930jdvvN3K/55zzog3bFwAAex9njAAAgMFTGAEAAIM3mKF0+/pwMUPFAABg7ZwxAgAABk9hBAAADJ7CCAAAGDyFEQAAMHgKIwAAYPAURgAAwOApjAAAgMFTGAEAAIOnMAIAAAZPYQQAAAyewggAABg8hREAADB4CiMAAGDwFEYAAMDgKYwAAIDBUxgBAACDpzACAAAGb+tmBwCMnH766dm1a1cOOeSQnHHGGZsdDgDAoCiMYA+xa9eu3HDDDZsdBgDAIPU6lK6qnlpVV1fVNVX1ygnrn1dVl3W3j1fVw2ftCwAAsCi9FUZVtSXJm5Mcn+ToJM+tqqOXNft8kse11o5J8r+SnDVHXwAAgIXo84zRsUmuaa1d21q7Lcm5SU4Yb9Ba+3hr7Wvd04uSHDprXwAAgEXpszB6UJLrx57v7JZN8+Ik75m3b1WdUlU7qmrHzTffvI5wAQCAoepz8oWasKxNbFh1XEaF0U/N27e1dla6IXjbtm2b2AYAAPpiZtl9Q5+F0c4kh409PzTJjcsbVdUxSd6a5PjW2lfm6QsAAJvNzLL7hj6H0l2c5KiqOrKq9ktyYpLt4w2q6vAk70zy/NbaZ+bpCwAAsCi9nTFqre2uqpcmeV+SLUnObq1dWVWnduvPTPJbSe6f5C1VlSS7W2vbpvXtK1YAAGDYer3Aa2vt/CTnL1t25tjjk5OcPGtfAACAPvR6gVcAAIC9gcIIAAAYPIURAAAweAojAABg8BRGAADA4CmMAACAwVMYAQAAg6cwAgAABk9hBAAADJ7CCAAAGLytmx0Aw7J1673udA8AAHsChREb6uCDn7jZIQAAwF0YSgcAAAyewggAABg8hREAADB4CiMAAGDwTL7QAzOvAQDA3kVh1AMzrwEAQHL66adn165dOeSQQ3LGGWdsdjgrUhgBAAC92LVrV2644YbNDmMmvmMEAAAMnsIIAAAYPIURAAAweAojAABg8BRGAADA4CmMAACAwVMYAQAAg6cwAgAABs8FXgH2YnvTFcUBYE+mMALYi+1NVxQHgD2ZoXQAAMDgKYwAAIDBM5QOVnDSSW/bsH3ddNM3br/fyP2ec86LNmxfAAB7KmeMAACAwXPGCNjjmXkNAOibwgjY45l5DQDom6F0AADA4CmMAACAwZt5KF1VbUnygPE+rbUv9BEUAACsh5llmddMhVFV/WqSVyW5Kcl3u8UtyTE9xQUAALBhZh1K92tJfqi19sOttYd1t1WLoqp6alVdXVXXVNUrJ6x/aFVdWFW3VtUrlq27rqour6pLq2rHjHECAADMbdahdNcn+fo8G+6G3r05yZOS7ExycVVtb61dNdbsq0leluSZUzZzXGvty/PsFwBYmSnwWQvHDfu6WQuja5N8qKreneTWpYWttd9boc+xSa5prV2bJFV1bpITktxeGLXWvpTkS1X19HkDBwDWxhT4rIXjhn3drEPpvpDkA0n2S3LvsdtKHpTRmaYlO7tls2pJ3l9Vl1TVKdMaVdUpVbWjqnbcfPPNc2weAABgZNUzRt2QuKNaa78057ZrwrI2R//HtNZurKqDk3ygqj7dWvvIXTbY2llJzkqSbdu2zbN9APZhhv0AMI9Vzxi11r6T5KCq2m/Obe9MctjY80OT3Dhr59bajd39l5Kcl9HQPACYydKwn127dm12KADsBWb9jtF1ST5WVduTfGtp4SrfMbo4yVFVdWSSG5KcmOQXZ9lZVR2Q5G6ttW92j5+c5DUzxgoAADCXWQujG7vb3bL6d4uSJK213VX10iTvS7IlydmttSur6tRu/ZlVdUiSHUnuk+S7VXVakqOTHJjkvKpaivEdrbX3zv5jAQAAzG6mwqi19ttr2Xhr7fwk5y9bdubY410ZDbFb7htJHr6WfQIAAMxrpsKoqi7IhIkTWmtPWHhEAAAAG2zWoXSvGHu8f5JnJ9m9+HAAAAA23qxD6S5ZtuhjVfXhHuIBAADYcLMOpfvesad3S/LjSQ7pJSIAAIANNutQuksy+o5RZTSE7vNJXtxXUAAAm8GFgWG4Zh1Kd2TfgQAAbLalCwMDwzPrGaNU1aOTHDHep7X29h5iAgAA2FCzfsfoT5M8JMmlSb7TLW5JFEYAAMBeb9YzRtuSHN1au8u1jAAAgL3HSSe9bcP2ddNN37j9fiP3e845L5q7z91mbHdFzEIHAADso1Y8Y1RVf5fRkLl7J7mqqj6R5Nal9a21Z/QbHgAAQP9WG0q3PckDknx02fLHJTFlCwAAsE9YrTA6Icl/b61dNr6wqr6V5FVJ/rivwAAAADbKat8xOmJ5UZQkrbUdGU3dDQAAsNdbrTDaf4V137PIQAAAADbLaoXRxVX1y8sXVtWLk1zST0gAAAAba7XvGJ2W5Lyqel7uKIS2JdkvybP6DAwAAGCjrFgYtdZuSvLoqjouyY90i9/dWvtg75EBAABskNXOGCVJWmsXJLmg51gA9gmuKA4Ae5/VvmMEAACwz1MYAQAAg6cwAgAABm+m7xgB/du69V53ugcAYOMojGAPcfDBT9zsEAAABkthBKyJmdcAgH2J7xgBAACDpzACAAAGz1A6ANgDGJ7KWjhuYHEURgAAsA5mlt03KIwAAGAdzCy7b1AYAbBhDPsBYE9l8gUAAGDwFEYAAMDgKYwAAIDBUxgBAACDpzACAAAGT2EEAAAMnsIIAAAYvF4Lo6p6alVdXVXXVNUrJ6x/aFVdWFW3VtUr5ukLAACwKL0VRlW1Jcmbkxyf5Ogkz62qo5c1+2qSlyX5P2voCwAAsBBbe9z2sUmuaa1dmyRVdW6SE5JctdSgtfalJF+qqqfP2xcAGIaTTnrbhu3rppu+cfv9Ru73nHNetGH7Aibrcyjdg5JcP/Z8Z7es774AAABz6bMwqgnL2qL7VtUpVbWjqnbcfPPNMwcHAACwpM/CaGeSw8aeH5rkxkX3ba2d1Vrb1lrbdtBBB60pUAAAYNj6LIwuTnJUVR1ZVfslOTHJ9g3oCwAA7AG2br1Xtm69d7Zuvddmh7Kq3iZfaK3trqqXJnlfki1Jzm6tXVlVp3brz6yqQ5LsSHKfJN+tqtOSHN1a+8akvn3FCgAALN7BBz9xs0OYWZ+z0qW1dn6S85ctO3Ps8a6MhsnN1BcAAKAPvV7gFQAAYG+gMAIAAAZPYQQAAAyewggAABg8hREAADB4CiMAAGDwFEYAAMDg9XodIwD6tXQl8b3hiuIAsCdTGAHsxfamK4oDwJ7MUDoAAGDwnDEC9niGiwEAfVMYAXs8w8UAgL4ZSgcAAAyewggAABg8hREAADB4CiMAAGDwTL4AAANjpkfWwnHDvk5hBAADY6ZH1sJxw77OUDoAAGDwnDECYJ9k2A8A81AYAbBPMuwHgHkYSgcAAAyewggAABg8hREAADB4CiMAAGDwFEYAAMDgmZUOAKBjmncYLoURAEDHNO8wXIbSAQAAg6cwAgAABk9hBAAADJ7CCAAAGDyFEQAAMHgKIwAAYPAURgAAwOApjAAAgMFTGAEAAIOnMAIAAAZPYQQAAAxer4VRVT21qq6uqmuq6pUT1ldVvbFbf1lV/djYuuuq6vKqurSqdvQZJwAAMGxb+9pwVW1J8uYkT0qyM8nFVbW9tXbVWLPjkxzV3X4iyR9290uOa619ua8YAQAAkn7PGB2b5JrW2rWttduSnJvkhGVtTkjy9jZyUZL7VtUDe4wJAADgLvosjB6U5Pqx5zu7ZbO2aUneX1WXVNUpvUUJAAAMXm9D6ZLUhGVtjjaPaa3dWFUHJ/lAVX26tfaRu+xkVDSdkiSHH374euIFAAAGqs8zRjuTHDb2/NAkN87aprW2dP+lJOdlNDTvLlprZ7XWtrXWth100EELCh0AABiSPguji5McVVVHVtV+SU5Msn1Zm+1JXtDNTveoJF9vrX2xqg6oqnsnSVUdkOTJSa7oMVYAAGDAehtK11rbXVUvTfK+JFuSnN1au7KqTu3Wn5nk/CRPS3JNkm8nOanr/oAk51XVUozvaK29t69YAQCAYevzO0ZprZ2fUfEzvuzMscctyUsm9Ls2ycP7jA0AAGBJrxd4BQAA2BsojAAAgMFTGAEAAIOnMAIAAAZPYQQAAAyewggAABg8hREAADB4CiMAAGDwFEYAAMDgKYwAAIDBUxgBAACDpzACAAAGT2EEAAAMnsIIAAAYPIURAAAweAojAABg8BRGAADA4CmMAACAwVMYAQAAg6cwAgAABk9hBAAADJ7CCAAAGDyFEQAAMHgKIwAAYPAURgAAwOApjAAAgMFTGAEAAIOnMAIAAAZPYQQAAAyewggAABg8hREAADB4CiMAAGDwFEYAAMDgKYwAAIDBUxgBAACDpzACAAAGT2EEAAAMnsIIAAAYPIURAAAweL0WRlX11Kq6uqquqapXTlhfVfXGbv1lVfVjs/YFAABYlN4Ko6rakuTNSY5PcnSS51bV0cuaHZ/kqO52SpI/nKMvAADAQvR5xujYJNe01q5trd2W5NwkJyxrc0KSt7eRi5Lct6oeOGNfAACAheizMHpQkuvHnu/sls3SZpa+AAAAC1GttX42XPVzSZ7SWju5e/78JMe21n51rM27k/xOa+0fuud/n+T0JA9ere/YNk7JaBhekvxQkqt7+YHmd2CSL292EHsouZlObqaTm+nkZjq5mU5uppOb6eRmOrmZbk/Lzfe31g5avnBrjzvcmeSwseeHJrlxxjb7zdA3SdJaOyvJWesNdtGqakdrbdtmx7Enkpvp5GY6uZlObqaTm+nkZjq5mU5uppOb6faW3PQ5lO7iJEdV1ZFVtV+SE5NsX9Zme5IXdLPTPSrJ11trX5yxLwAAwEL0dsaotba7ql6a5H1JtiQ5u7V2ZVWd2q0/M8n5SZ6W5Jok305y0kp9+4oVAAAYtj6H0qW1dn5Gxc/4sjPHHrckL5m1715mjxvetweRm+nkZjq5mU5uppOb6eRmOrmZTm6mk5vp9orc9Db5AgAAwN6iz+8YAQAA7BUURgAAwODtk4VRVX1PVX24qrZMWHePqvqLqrqmqv5fVR0xZRs/XlWXd+3eWFXVLf/pqvrHqtpdVc+ZMZ6J25rQ7je6NldX1VPGln+oW3Zpdzt4pViq6iFdu1um5aSqXlhVn+1uL5wSz9RcVdV3xuLZPrb8pV37VlUHzpif9cZyeFW9v6r+qaquWlpXVX/W5e2Kqjq7qu7eLf+Fbjvv6ik3c8XTV26q6rix39GlVfVvVfXMbt3E31OfuVlLPJuUmyfU6O/qiqr6k6rausm5mRhPX7np1p1RVVd2x/D4/7+PjsV4Y1X9Td+5WUs8Pefmdd3v4oqq+oWx5W+rqs+PxfOISblZJbZF522uWBeQt5lfk9ZjjXnq5bW7qu5fVRdU1S1V9aax5fesqndX1ae7Y/d3x9a9vKq+MN5+PRaZj6p6RFVd2MV82fhxs8L+Z31f9dqqun75cVBVp3Z5vrSq/qGqju6Wr/u4WXBuvr+qLuliun0ysVX2v97cvGHs7/QzVfUv3fKF/k2N7W+R+TqupryurbD/U6vqBTPE+efd8fnyqnp9Ve2qqlfM+/NO1Frb524ZTejwa1PW/ZckZ3aPT0zyF1PafSLJTyapJO9Jcny3/IgkxyR5e5LnzBjPxG0ta3N0kk8luUeSI5N8LsmWbt2Hkmyb0GfFWJLcMiknSb43ybXd/f26x/ebJ1fj217W50e7uK5LcuAMuVlELB9K8qTu8b2S3LN7/LQu55Xkz5P8ylifxyd5V0+5mTuevnKzbFtfHYtl6u+pz9ysJZ6NzE1GHxZdn+QHu3WvSfLizcrNavH0kZskj07ysYxmBN2S5MIkj5/Q/6+TvKDv3Kw1np5y8/QkH8ho4qIDkuxIcp9u3dsy5TVhPDerxLfIvK0p1nXm7YjM+Jq0ntsa87RibFP2M8tr9wFJfirJqUneNLb8nkmO6x7vl+Sj4/2TvGi8/Z6SjyQ/mOSo7vH3Jflikvuusv9Z31c9KskDlx8HS8dl9/gZSd67qONmwbnZL8k9usf3yuj16vv6zM2yNr+a0SzNC/+b6iNfy9rc6TV/nTEekuSfly17dZJXLCIH++QZoyTPS/K3U9adkORPusd/leRnln8KVFUPzOgP9cI2yvjbkzwzSVpr17XWLkvy3VkCWWlbE+I6t7V2a2vt8xlNYX7sStueM5bxnDwlyQdaa19trX0toxfPp06JacVcTYjpk62162aIZ8m6Yuk+WdraWvtAt/9bWmvf7h6f3zoZvcAdOiWGheVmQfEsJDfL2jwnyXvGYpn199TXcbPWeJb0Fcv9k9zaWvtMt+4DSZ49JYaNyM088SxZbywtyf7p3gQkuXuSm8Y7VtW9kzwhybQzNIvMzSLiWbLeWI5O8uHW2u7W2rcy+jBrUv+1WmTeFhnrTLHM+/q4DnPnqa/X7tbat1pr/5Dk35Yt/3Zr7YLu8W1J/jGr/89fq4Xlo7X2mdbaZ7vHNyb5UpKDVtn/TO8VWmsXtdG1Kpcv/8bY0wMy+ptflEXm5rbW2q3d03tktlFX68rNMs/N6EPVPvX1t3Wn1/xpqurVS2d+ajRa6nVV9YnubNlju2bvT3JwdxbqsdO3tjb7XGFUowvCPniFN1kPyugT2LTWdif5ekZvPpa32Tn2fGe3bC1m3dbtcU1pd053EPzP1YqT5SbkZLV93SWmCbnav6p2VNVFq50aXcV6Y/nBJP9SVe+sqk92p1TvNISyRkPWnp/kvcs32kNu1hXPtH2sMZZxJ2bOf6g9HTdrjmfaPhYcy5eT3L2qlq7O/Zwkhy3f6AbmZqZ4pu1jLbG01i5MckFGnxR/Mcn7Wmv/tKzvs5L8/bI3NEkWn5v1xjNtH2uJJaPi4vgaDZM6MMlxufPv47Xd8I43VNU9VonlTno4phYZ66yx9G4deZrXwt4HVNV9k/ynJH+/gLiWb7u3fFTVsRl9IPG5VZrO8n9ttX29pKo+l+SMJC+bP9qJ21x4bqrqsKq6rNvO67ricSXrzk233+/PaDTRB+ftO8c++vzbWutr/tbW2rFJTkvyqm7ZM5J8rrX2iNbaR9cYz1T7XGGU5MAk/7LC+klFxfJPJ2ZpM6tZt7VSu+e11h6W5LHd7flzxrA8J4uI6fDW2rYkv5jk96vqIXPGtKhYtmaUk1ckeWSSB2c0RGHcW5J8ZMof0KJzs954ZtnHXO26Tz4fltEFk+fRx3Gznnhm3sdaY+k+GT4xyRuq6hNJvplk94RtbEhu5ohn5n2s1q6qfiDJf8zo0+0HJXlCVf30snYrfXK50NwsIJ5V9zFru9ba+zO6vt7Hu/1dmDt+H7+R5KEZ/d1/b5L/NkM84xaatwXHusjXxPVaa57mtZDt1ug7gX+e5I2ttWvXHdVd9ZKP7n/RnyY5qbW22lm2de+ztfbm1tpDMjoW/8c8fVew8Ny01q5vrR2T5AeSvLCqHrBKl0Udnycm+avW2nfW0HdWfR5La33Nf2d3f0lGQ/Z6ty8WRv+a0bCLJLd/oe3Sqrq0W7Qz3adm3T+s/5DRuMdxO3PnU96HJlntU4FpZt3W7XEtb9dau6G7/2aSd2SVIXYT3CknK+1rWkzLc7X0KUn3j/5DGX1HZC3WG8vOJJ9srV3bfRrzN0l+bKlTVb0qo2EA/3XK/hedm/XGM3Efa4xlyc8nOa+19u8z7HPcwo+bdcYzcR+LjqUbOvPY7lOqjyT57ITtblhuZoxn4j7WGMuzklzURsNAb8nouxWPWupUVffP6H/Qu6fsf9G5WW88E/exxljSWntt90nlkzJ647A07OiLbeTWJOdkz/g/vahYZ41lI6w1T/Na1PuAs5J8trX2+wuIaZKF56Oq7pPR39P/aK1dNEOXWd5XzercTP66wVr0dqx074GuzOiD0JUsKjfrHWUxi77ytZ7X/KWhi9/J6IPn3u1zhVE3DnJLVe3fPf/N7oVhadad7Ule2D1+TpIPdp/Kjm/ji0m+WVWP6oatvSDTv7N0u6r69IR4Zt3W9iQn1mgGkyOTHJXkE1W1tRsGsTQE62eTXLFaLMtiuFNOMqran1xV96uq+yV5ciZX8hNz1fW7RxfTgUkek+SqlWKoqmOr6u0TVq0rliQXJ7lfVS2NgX7CUixVdXJGY2SfO+0Tr0XnZi3x9JibJWsal9xDbuaOZzNyU3fM+niPjD69PHP5RjcyN9Pi6TE3X0jyuO5/z92TPC7J+NC1n8toIoE7fadiSQ+5mTuevnJTVVu6QixVdUxGXzh+f/f8gd19ZfTGbrP/T88d6wLy1rt15Gmqdb52r7Td/53RG+HT5uk3j0Xno0bDqc5L8vbW2l8uW/c7VfWsCd1WfV+1yj6PGnv69Kz+4c9MesjNoVX1Pd3j+2X03ufq7nkvuem2/UMZTX5w4Tz95tXH31Zn0uvatHxtvrbA2Sz2lFuSP07yxCnr9k/ylxlNbvCJjMZTLq27dOzxtoxeLD6X5E1Jqlv+yIyq6G8l+UqSK7vlBya5eso+p23rGUleM9buN7s2V+eOWfAOyOgU4mUZfTrxB7ljtrqJsYxt75ZpOUnyn7scXJPRqfKl5a9J8oyVcpXRLFGXZzSG/fLcedaul3Ux7c7ok4W3dsufk+SPpuRnzbF0657U5efyjGZb2q9bvrvL56Xd7bfG+jw+d8ygtbDcrCWennNzRJIbktxt2XYn/p42IDdzxbNJuXl9Rm+8r05y2rJ1m5GbifH0lZuMZn77o26fVyX5vWXb/lCSp07YZy+5WUs8PeZm/y6Gq5JclOQRY/0/mNHf/BVJ/m+Se03KzUq3Bedt7lgXkLeZX5PWc1tjnvp87b4uo7MAt3T7ODqjT9dbd9wu/c8/eazPi7K4WekWmY9fSvLvYzFfunTsJHlXkp+csP9Z31ed0e3zu939q7vlf5DR+5tLM/o+4Q8v6rhZcG6WXts/1d2fMta/l9x0616d5Hen/HyLnpVuYfnq1h2Rya9r0/L16nSzy2VsRuaM/k6vG9vmFdP6rTsHi0zonnLLaFjXn27wPn82ycs2+2dfFtN4YbThOVkWy+uTHLPZORmL5/G5402c3MiN3MjNhuRmlXb7dN4W9SZukXnarNfuLLYw2pDjJqOJTzY0T91+11MYyc0A8rXIwmifG0qXjKb+TXJBTbjAa4/7fFdr7Y0btb+VVHfhr4xNabsZORnXWvv1NprOcdPV6IJ1b0nytURuxsnNdHIzndxMtzw3K9lX8zbpNWk9FpmnzXjtrqqXZzQBxmqzKM5ko46b1tpTVm+1OIs4buRmPntjvqrq9Rmd6fzWQrbXVVoAAACDtU+eMQIAAJiHwggAABg8hREAc6mq+1d3fbiq2lVVN4w9329Z29Oq6p4zbPNDVbVtwvK3VtXRq/R95nibqnpbVT1nnp9p2fY+vo6+j6+qR6+1PwCbR2EEwFxaa19pd1wf7swkb1h63lq7bVnz05KsWhitsK+TW2srXicto2vxrFg8zbnP9RQ2j8/okgYA7GUURgCsW1X9TFV9sqour6qza3Sx6pcl+b6MZjm6oGv3h1W1o6qurKrfnmG7t59Jqqpbquq1VfWpqrqoqh7QnZ15RpLXd2esHrLKtt5QVR+pqn+qqkdW1Tur6rPdxTiX2t3S3T++6/NXVfXpqvqz7mKfqYUE1y4AAAKGSURBVKrr6o6Lb2/r2h2R5NQkL+9ieWxVHVRVf11VF3e3x3R9Hjd2lu2TVXXvteQdgMVRGAGwXvtndDHjX2itPSzJ1iS/0k2DfGOS41prx3Vtf7O1ti3JMUkeV1XHzLGfA5Jc1Fp7eJKPJPnl1trHM7q6/K93Z6w+t8o2bmut/XRGZ7r+NslLkvxIkhdV1f0ntP/RjM56HZ3kwRld7X6i1tp1ufMZtI9mdPHKN7TWHpnk2Une2jV/RZKXdGfdHpvkX1f96QHolcIIgPXakuTzrbXPdM//JMlPT2n781X1j0k+meSHM98QuNsyumJ6klyS0RXQ57W9u788oyu0f7G1dmuSa5McNqH9J1prO1tr301y6Rr2+cQkb+quObI9yX26s0MfS/J73Vm1+7bWdq/hZwFggbZudgAA7PVmurBeVR2Z0ZmSR7bWvlZVb8vobNOs/r3dcfG972Rtr2G3dvffHXu89HzS9sbbjO9zd+74cHGln+FuSX6ytbb8jNDvVtW7kzwtyUVV9cTW2qdniB+AnjhjBMB67Z/kiKr6ge7585N8uHv8zSRL35+5T0ZF1Ner6gFJjl/Q/sf3sVGuS/Lj3eNnrxDL+5O8dOlJVT2iu39Ia+3y1trrkuxI8tBeowVgVQojANbr35KclOQvq+ryjM6+nNmtOyvJe6rqgtbapzIaQndlkrMzGk62COcm+fVuEoOpky8s2G8n+YOq+mhGZ5KW/F2SZy1NvpDkZUm2VdVlVXVVRpMzJMlpVXVFVX0qo+8XvWeD4gZgirpjVAIAAMAwOWMEAAAMnsIIAAAYPIURAAAweAojAABg8BRGAADA4CmMAACAwVMYAQAAg6cwAgAABu//A50olyJRGuNeAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1008x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(14,5))\n",
    "sns.barplot(x= 'share',y='Churn',data=df,color=\"blue\",saturation=0.25)\n",
    "plt.xlabel(\"Total intl minutes\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "why polynomial features extracts more information from data than KBinsDiscretizer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is it worth to try polynomial featues of degree more than 2?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Стохастический градиентый спуск в задачах классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Решим задачу методом стохастического градиентого спуска,\n",
    "применяя такую же трансформацю признаков, как в последней задаче:\n",
    "    - KBinsDiscretizer с разбиением на 25 групп и стратегией разбиения 'kmeans' к численным признакам,\n",
    "    - OneHotEncoder- к категориальным.\n",
    "Воспользуемся классом моделей градиентного спуска\n",
    "`sklearn.linear_model.SGDClassifier` с параметрами:\n",
    "- learning_rate='constant'\n",
    "- max_iter=20 (сколько раз каждый объект случайно выбирается для модификации весов)\n",
    "- loss='log'\n",
    "- alpha=0.0001 (сила регуляризации)\n",
    "- penalty='l2'\n",
    "-  сетка значений шага скорости обучения epsilon (learning rate): [0.001,0.01,0.05,0.1,0.2,0.5,1.0,1.5,5,10] (Возьмем достаточно большие значения для иллюстрации расходимости)\n",
    "\n",
    "SGDRegressor(loss='squared_error', penalty='l2') решает ту же задачу, что и Ridge() (др.solver)\n",
    "\n",
    "Просто и быстро работает.\n",
    "\n",
    "Чувствителен к масштабу признаков, требует гиперпараметры, от которых может заметно зависеть качество (регуляризация, max_iter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:570: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:570: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:570: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Test accuracy = 0.5907 learning rate= 0.0010\n",
      " Test accuracy = 0.6777 learning rate= 0.0100\n",
      " Test accuracy = 0.5757 learning rate= 0.0500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:570: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:570: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:570: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Test accuracy = 0.2834 learning rate= 0.1000\n",
      " Test accuracy = 0.3253 learning rate= 0.2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:570: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:570: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Test accuracy = 0.3193 learning rate= 0.5000\n",
      " Test accuracy = 0.3913 learning rate= 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:570: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:570: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Test accuracy = 0.8066 learning rate= 1.5000\n",
      " Test accuracy = 0.8501 learning rate= 5.0000\n",
      " Test accuracy = 0.8681 learning rate= 10.0000\n"
     ]
    }
   ],
   "source": [
    "results=[]\n",
    "for eps in [0.001,0.01,0.05,0.1,0.2,0.5,1.0,1.5,5,10]:\n",
    "    from sklearn.linear_model import SGDClassifier\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('ohe_and_scaling', column_transformer),\n",
    "        ('regression', SGDClassifier(max_iter=20,loss='log',penalty='l2',alpha=0.001, \n",
    "                                     learning_rate='constant',eta0=eps,\n",
    "                                     random_state=random_state,n_iter_no_change=20))\n",
    "    ])\n",
    "\n",
    "    model = pipeline.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(\" Test accuracy = %.4f learning rate= %.4f\" % (accuracy_score(y_pred,y_test), eps))\n",
    "    results.append((accuracy_score(y_pred,y_test), eps))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, как при  слишком большом learning rate SGD не сходится. Не достигает такого же качества как просто LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max test accuracy = 0.8681 \n",
      "learning rate= 10.0000\n"
     ]
    }
   ],
   "source": [
    "print(\"Max test accuracy = %.4f \\nlearning rate= %.4f\" % \n",
    "      (max(results, key = lambda i : i[0])[0],max(results, key = lambda i : i[0])[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полностью аналогично предыдущей задаче обучим модель с параметром learning_rate='adaptive'(делит eps на 5, если нет улучшения  training loss на нескольких итерациях(число задается другими параметрами). Если задать слишком большой eps, то очень возможно не справится, зависит, в частности, от параметра n_iter_no_change и др.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:570: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:570: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:570: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.6611694152923538 20\n",
      "2 0.7646176911544228 20\n",
      "3 0.46476761619190404 20\n",
      "10 0.6461769115442278 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:570: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\"Maximum number of iteration reached before \"\n"
     ]
    }
   ],
   "source": [
    "results=[]\n",
    "for eps in [1,2,3,10]:\n",
    "    from sklearn.linear_model import SGDClassifier\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('ohe_and_scaling', column_transformer),\n",
    "        ('regression', SGDClassifier(max_iter=20,loss='log',penalty='l2',alpha=0.001,\n",
    "                                     learning_rate='adaptive',eta0=eps,\n",
    "                                     random_state=random_state,n_iter_no_change=5 ))\n",
    "    ])\n",
    "\n",
    "    model = pipeline.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(eps,accuracy_score(y_pred,y_test),model[1].n_iter_)\n",
    "    results.append((accuracy_score(y_pred,y_test), eps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4725 candidates, totalling 23625 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 23625 out of 23625 | elapsed:  5.9min finished\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'NC'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    763\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 765\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    766\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[0;32m    723\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0man\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mof\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    724\u001b[0m         \"\"\"\n\u001b[1;32m--> 725\u001b[1;33m         return self._fit(X, y, alpha=self.alpha, C=1.0,\n\u001b[0m\u001b[0;32m    726\u001b[0m                          \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m                          \u001b[0mcoef_init\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcoef_init\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mintercept_init\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mintercept_init\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, alpha, C, loss, learning_rate, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[0;32m    537\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    538\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 539\u001b[1;33m         X, y = self._validate_data(X, y, accept_sparse='csr',\n\u001b[0m\u001b[0;32m    540\u001b[0m                                    \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"C\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    541\u001b[0m                                    accept_large_sparse=False)\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    430\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    794\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"y cannot be None\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    795\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 796\u001b[1;33m     X = check_array(X, accept_sparse=accept_sparse,\n\u001b[0m\u001b[0;32m    797\u001b[0m                     \u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    798\u001b[0m                     \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    597\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unsafe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'NC'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'loss': ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron'],\n",
    "    'penalty': ['elasticnet', 'l2', 'l1'],\n",
    "    'alpha': [10 ** x for x in range(-6, 1)],\n",
    "    'l1_ratio': [0, 0.05, 0.1, 0.2, 0.5, 0.8, 0.9, 0.95, 1],\n",
    "    'learning_rate' : [\"optimal\"], \n",
    "    'max_iter' : [100, 500, 1000, 1500, 2000]\n",
    "}\n",
    "\n",
    "sdgc = SGDClassifier()\n",
    "\n",
    "gs_sgdc = GridSearchCV(sdgc, param_grid=param_grid, cv=5, scoring=\"accuracy\", verbose=1)\n",
    "gs_sgdc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
